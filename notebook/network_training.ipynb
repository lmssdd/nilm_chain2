{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b6c3d26-334e-40e2-b5e7-b1a5fb4dc12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f707559-2e56-4496-aa1c-ea01e66da91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in /root/.local/lib/python3.9/site-packages (3.7.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tables) (21.3)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in /root/.local/lib/python3.9/site-packages (from tables) (2.8.3)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.9/dist-packages (from tables) (1.23.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from packaging->tables) (3.0.9)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.9/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/__main__.py\", line 31, in <module>\n",
      "    sys.exit(_main())\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.9/logging/__init__.py\", line 952, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.9/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.1', new='22.2.2'),)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba3b5da-a543-4e2c-9fd9-cc5b95fa40ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE = ['fridge', 'dish_washer', 'washing_machine']\n",
    "THRESHOLD = [50., 10., 20.]\n",
    "MIN_ON = [1., 30., 30.]\n",
    "MIN_OFF = [1., 3., 30.]\n",
    "\n",
    "METER = 'aggregate'\n",
    "SEQ_LEN = 60*8\n",
    "BORDER = 16\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "MAX_POWER = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721d0b83-ea9e-4f00-adb4-a582e02fd6cc",
   "metadata": {},
   "source": [
    "# UKDale training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d621239f-ab4f-4281-8ea1-7d13667ea723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import get_status\n",
    "houses=[1,2,5]\n",
    "ds_meter = []\n",
    "ds_appliance = []\n",
    "ds_status = []\n",
    "for i in houses:\n",
    "    ds = pd.read_feather('../data/ukdale/feather_files/UKDALE_%d_train.feather' %(i))\n",
    "    ds.set_index('datetime', inplace=True)\n",
    "  \n",
    "    meter = ds[METER]\n",
    "    appliances = ds[APPLIANCE]\n",
    "    \n",
    "    status = pd.DataFrame()\n",
    "    for a in range(len(APPLIANCE)):\n",
    "        status = pd.concat([status, get_status(ds[APPLIANCE[a]], THRESHOLD[a], MIN_OFF[a], MIN_ON[a])], axis=1)\n",
    "    \n",
    "    ds_meter.append(meter)\n",
    "    ds_appliance.append(appliances)\n",
    "    ds_status.append(status)\n",
    "\n",
    "ds_len = [len(ds_meter[i]) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ba56dc-d29b-4258-8eeb-dccf7cc894ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.preprocessing import Power\n",
    "\n",
    "ds_house_train = [Power(ds_meter[i][:int(0.8*ds_len[i])], \n",
    "                        ds_appliance[i][:int(0.8*ds_len[i])], \n",
    "                        ds_status[i][:int(0.8*ds_len[i])], \n",
    "                        SEQ_LEN, BORDER, MAX_POWER, True) for i in range(3)]\n",
    "\n",
    "ds_house_valid = [Power(ds_meter[i][int(0.8*ds_len[i]):], \n",
    "                        ds_appliance[i][int(0.8*ds_len[i]):],\n",
    "                        ds_status[i][int(0.8*ds_len[i]):], \n",
    "                        SEQ_LEN, BORDER, MAX_POWER, False) for i in range(3)]\n",
    "\n",
    "ds_house_total  = [Power(ds_meter[i], ds_appliance[i], ds_status[i], \n",
    "                         SEQ_LEN, BORDER, MAX_POWER, False) for i in range(3)]\n",
    "\n",
    "ds_train = torch.utils.data.ConcatDataset([ds_house_train[0], ds_house_train[2]])\n",
    "ds_valid = torch.utils.data.ConcatDataset([ds_house_valid[0], ds_house_valid[2]])\n",
    "\n",
    "dl_train = DataLoader(dataset = ds_train, batch_size = BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "dl_valid = DataLoader(dataset = ds_valid, batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "dl_test = DataLoader(dataset = ds_house_total[1], batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "dl_house_test = [DataLoader(dataset = ds_house_total[1], batch_size = 1, shuffle=False)]\n",
    "dl_house_valid = [DataLoader(dataset = ds_house_valid[i], batch_size = 1, shuffle=False) for i in [0,2]]\n",
    "dl_house_total = [DataLoader(dataset = ds_house_total[i], batch_size = 1, shuffle=False) for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe51444-765c-47a9-82a5-ea7ecd25dcac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/200] train_loss: 0.68969 valid_loss: 0.62037 test_loss: 0.61620 \n",
      "Validation loss decreased (inf --> 0.620375).  Saving model ...\n",
      "[  2/200] train_loss: 0.57958 valid_loss: 0.51104 test_loss: 0.49913 \n",
      "Validation loss decreased (0.620375 --> 0.511041).  Saving model ...\n",
      "[  3/200] train_loss: 0.48308 valid_loss: 0.43294 test_loss: 0.41793 \n",
      "Validation loss decreased (0.511041 --> 0.432945).  Saving model ...\n",
      "[  4/200] train_loss: 0.41068 valid_loss: 0.37957 test_loss: 0.35901 \n",
      "Validation loss decreased (0.432945 --> 0.379569).  Saving model ...\n",
      "[  5/200] train_loss: 0.36150 valid_loss: 0.34452 test_loss: 0.31808 \n",
      "Validation loss decreased (0.379569 --> 0.344517).  Saving model ...\n",
      "[  6/200] train_loss: 0.32845 valid_loss: 0.31971 test_loss: 0.29074 \n",
      "Validation loss decreased (0.344517 --> 0.319713).  Saving model ...\n",
      "[  7/200] train_loss: 0.30117 valid_loss: 0.29839 test_loss: 0.26757 \n",
      "Validation loss decreased (0.319713 --> 0.298387).  Saving model ...\n",
      "[  8/200] train_loss: 0.28015 valid_loss: 0.28124 test_loss: 0.24740 \n",
      "Validation loss decreased (0.298387 --> 0.281236).  Saving model ...\n",
      "[  9/200] train_loss: 0.26327 valid_loss: 0.26395 test_loss: 0.22827 \n",
      "Validation loss decreased (0.281236 --> 0.263954).  Saving model ...\n",
      "[ 10/200] train_loss: 0.24747 valid_loss: 0.24982 test_loss: 0.21490 \n",
      "Validation loss decreased (0.263954 --> 0.249822).  Saving model ...\n",
      "[ 11/200] train_loss: 0.23479 valid_loss: 0.23713 test_loss: 0.19940 \n",
      "Validation loss decreased (0.249822 --> 0.237126).  Saving model ...\n",
      "[ 12/200] train_loss: 0.22620 valid_loss: 0.22658 test_loss: 0.18971 \n",
      "Validation loss decreased (0.237126 --> 0.226576).  Saving model ...\n",
      "[ 13/200] train_loss: 0.21167 valid_loss: 0.21731 test_loss: 0.17907 \n",
      "Validation loss decreased (0.226576 --> 0.217307).  Saving model ...\n",
      "[ 14/200] train_loss: 0.20504 valid_loss: 0.21065 test_loss: 0.17188 \n",
      "Validation loss decreased (0.217307 --> 0.210648).  Saving model ...\n",
      "[ 15/200] train_loss: 0.19546 valid_loss: 0.20322 test_loss: 0.16246 \n",
      "Validation loss decreased (0.210648 --> 0.203225).  Saving model ...\n",
      "[ 16/200] train_loss: 0.19042 valid_loss: 0.19611 test_loss: 0.15538 \n",
      "Validation loss decreased (0.203225 --> 0.196107).  Saving model ...\n",
      "[ 17/200] train_loss: 0.18345 valid_loss: 0.19362 test_loss: 0.15325 \n",
      "Validation loss decreased (0.196107 --> 0.193625).  Saving model ...\n",
      "[ 18/200] train_loss: 0.17885 valid_loss: 0.18680 test_loss: 0.14592 \n",
      "Validation loss decreased (0.193625 --> 0.186796).  Saving model ...\n",
      "[ 19/200] train_loss: 0.17575 valid_loss: 0.18446 test_loss: 0.14281 \n",
      "Validation loss decreased (0.186796 --> 0.184457).  Saving model ...\n",
      "[ 20/200] train_loss: 0.17131 valid_loss: 0.18361 test_loss: 0.14038 \n",
      "Validation loss decreased (0.184457 --> 0.183609).  Saving model ...\n",
      "[ 21/200] train_loss: 0.16937 valid_loss: 0.17825 test_loss: 0.13349 \n",
      "Validation loss decreased (0.183609 --> 0.178247).  Saving model ...\n",
      "[ 22/200] train_loss: 0.16826 valid_loss: 0.17668 test_loss: 0.13327 \n",
      "Validation loss decreased (0.178247 --> 0.176682).  Saving model ...\n",
      "[ 23/200] train_loss: 0.16473 valid_loss: 0.17426 test_loss: 0.13172 \n",
      "Validation loss decreased (0.176682 --> 0.174259).  Saving model ...\n",
      "[ 24/200] train_loss: 0.15984 valid_loss: 0.17107 test_loss: 0.12798 \n",
      "Validation loss decreased (0.174259 --> 0.171066).  Saving model ...\n",
      "[ 25/200] train_loss: 0.15786 valid_loss: 0.17099 test_loss: 0.12824 \n",
      "Validation loss decreased (0.171066 --> 0.170990).  Saving model ...\n",
      "[ 26/200] train_loss: 0.15937 valid_loss: 0.17038 test_loss: 0.12387 \n",
      "Validation loss decreased (0.170990 --> 0.170383).  Saving model ...\n",
      "[ 27/200] train_loss: 0.15489 valid_loss: 0.16542 test_loss: 0.11983 \n",
      "Validation loss decreased (0.170383 --> 0.165417).  Saving model ...\n",
      "[ 28/200] train_loss: 0.15246 valid_loss: 0.16401 test_loss: 0.12004 \n",
      "Validation loss decreased (0.165417 --> 0.164006).  Saving model ...\n",
      "[ 29/200] train_loss: 0.15304 valid_loss: 0.16794 test_loss: 0.12161 \n",
      "[ 30/200] train_loss: 0.15274 valid_loss: 0.16349 test_loss: 0.11913 \n",
      "Validation loss decreased (0.164006 --> 0.163486).  Saving model ...\n",
      "[ 31/200] train_loss: 0.15079 valid_loss: 0.16123 test_loss: 0.11710 \n",
      "Validation loss decreased (0.163486 --> 0.161226).  Saving model ...\n",
      "[ 32/200] train_loss: 0.14335 valid_loss: 0.16122 test_loss: 0.11409 \n",
      "Validation loss decreased (0.161226 --> 0.161225).  Saving model ...\n",
      "[ 33/200] train_loss: 0.14782 valid_loss: 0.16044 test_loss: 0.11465 \n",
      "Validation loss decreased (0.161225 --> 0.160439).  Saving model ...\n",
      "[ 34/200] train_loss: 0.14824 valid_loss: 0.16106 test_loss: 0.11650 \n",
      "[ 35/200] train_loss: 0.14417 valid_loss: 0.15552 test_loss: 0.11099 \n",
      "Validation loss decreased (0.160439 --> 0.155516).  Saving model ...\n",
      "[ 36/200] train_loss: 0.13962 valid_loss: 0.15786 test_loss: 0.11207 \n",
      "[ 37/200] train_loss: 0.14082 valid_loss: 0.15675 test_loss: 0.11356 \n",
      "[ 38/200] train_loss: 0.13488 valid_loss: 0.15634 test_loss: 0.11184 \n",
      "[ 39/200] train_loss: 0.13811 valid_loss: 0.15445 test_loss: 0.10979 \n",
      "Validation loss decreased (0.155516 --> 0.154455).  Saving model ...\n",
      "[ 40/200] train_loss: 0.13439 valid_loss: 0.15191 test_loss: 0.10765 \n",
      "Validation loss decreased (0.154455 --> 0.151912).  Saving model ...\n",
      "[ 41/200] train_loss: 0.13744 valid_loss: 0.15358 test_loss: 0.10831 \n",
      "[ 42/200] train_loss: 0.13511 valid_loss: 0.15236 test_loss: 0.10922 \n",
      "[ 43/200] train_loss: 0.13723 valid_loss: 0.14994 test_loss: 0.10850 \n",
      "Validation loss decreased (0.151912 --> 0.149940).  Saving model ...\n",
      "[ 44/200] train_loss: 0.13086 valid_loss: 0.15286 test_loss: 0.10968 \n",
      "[ 45/200] train_loss: 0.13389 valid_loss: 0.14974 test_loss: 0.10732 \n",
      "Validation loss decreased (0.149940 --> 0.149735).  Saving model ...\n",
      "[ 46/200] train_loss: 0.13319 valid_loss: 0.15075 test_loss: 0.10817 \n",
      "[ 47/200] train_loss: 0.13150 valid_loss: 0.14736 test_loss: 0.10505 \n",
      "Validation loss decreased (0.149735 --> 0.147359).  Saving model ...\n",
      "[ 48/200] train_loss: 0.13082 valid_loss: 0.14818 test_loss: 0.10632 \n",
      "[ 49/200] train_loss: 0.13099 valid_loss: 0.14766 test_loss: 0.10723 \n",
      "[ 50/200] train_loss: 0.12882 valid_loss: 0.14717 test_loss: 0.10725 \n",
      "Validation loss decreased (0.147359 --> 0.147171).  Saving model ...\n",
      "[ 51/200] train_loss: 0.12764 valid_loss: 0.14623 test_loss: 0.10518 \n",
      "Validation loss decreased (0.147171 --> 0.146232).  Saving model ...\n",
      "[ 52/200] train_loss: 0.12772 valid_loss: 0.14640 test_loss: 0.10691 \n",
      "[ 53/200] train_loss: 0.12622 valid_loss: 0.14404 test_loss: 0.10398 \n",
      "Validation loss decreased (0.146232 --> 0.144044).  Saving model ...\n",
      "[ 54/200] train_loss: 0.12679 valid_loss: 0.14328 test_loss: 0.10327 \n",
      "Validation loss decreased (0.144044 --> 0.143276).  Saving model ...\n",
      "[ 55/200] train_loss: 0.12729 valid_loss: 0.14569 test_loss: 0.10446 \n",
      "[ 56/200] train_loss: 0.12570 valid_loss: 0.14480 test_loss: 0.10421 \n",
      "[ 57/200] train_loss: 0.12474 valid_loss: 0.14119 test_loss: 0.10228 \n",
      "Validation loss decreased (0.143276 --> 0.141187).  Saving model ...\n",
      "[ 58/200] train_loss: 0.12100 valid_loss: 0.13996 test_loss: 0.10282 \n",
      "Validation loss decreased (0.141187 --> 0.139960).  Saving model ...\n",
      "[ 59/200] train_loss: 0.12475 valid_loss: 0.14060 test_loss: 0.10332 \n",
      "[ 60/200] train_loss: 0.12145 valid_loss: 0.13978 test_loss: 0.10239 \n",
      "Validation loss decreased (0.139960 --> 0.139782).  Saving model ...\n",
      "[ 61/200] train_loss: 0.12330 valid_loss: 0.14127 test_loss: 0.10610 \n",
      "[ 62/200] train_loss: 0.12250 valid_loss: 0.14386 test_loss: 0.10592 \n",
      "[ 63/200] train_loss: 0.12305 valid_loss: 0.14075 test_loss: 0.10357 \n",
      "[ 64/200] train_loss: 0.12360 valid_loss: 0.14153 test_loss: 0.10390 \n",
      "[ 65/200] train_loss: 0.12046 valid_loss: 0.13814 test_loss: 0.09984 \n",
      "Validation loss decreased (0.139782 --> 0.138145).  Saving model ...\n",
      "[ 66/200] train_loss: 0.11994 valid_loss: 0.13875 test_loss: 0.10323 \n",
      "[ 67/200] train_loss: 0.11835 valid_loss: 0.14110 test_loss: 0.10329 \n",
      "[ 68/200] train_loss: 0.12035 valid_loss: 0.14033 test_loss: 0.10333 \n",
      "[ 69/200] train_loss: 0.11933 valid_loss: 0.14017 test_loss: 0.10321 \n",
      "[ 70/200] train_loss: 0.11844 valid_loss: 0.13876 test_loss: 0.10176 \n",
      "[ 71/200] train_loss: 0.11669 valid_loss: 0.13548 test_loss: 0.09821 \n",
      "Validation loss decreased (0.138145 --> 0.135476).  Saving model ...\n",
      "[ 72/200] train_loss: 0.11750 valid_loss: 0.13496 test_loss: 0.09880 \n",
      "Validation loss decreased (0.135476 --> 0.134956).  Saving model ...\n",
      "[ 73/200] train_loss: 0.11592 valid_loss: 0.13781 test_loss: 0.10193 \n",
      "[ 74/200] train_loss: 0.11974 valid_loss: 0.13863 test_loss: 0.10154 \n",
      "[ 75/200] train_loss: 0.11402 valid_loss: 0.13615 test_loss: 0.09840 \n",
      "[ 76/200] train_loss: 0.11855 valid_loss: 0.13736 test_loss: 0.10202 \n",
      "[ 77/200] train_loss: 0.11408 valid_loss: 0.13549 test_loss: 0.10060 \n",
      "[ 78/200] train_loss: 0.11605 valid_loss: 0.13711 test_loss: 0.10230 \n",
      "[ 79/200] train_loss: 0.11585 valid_loss: 0.13541 test_loss: 0.10006 \n",
      "[ 80/200] train_loss: 0.11590 valid_loss: 0.13134 test_loss: 0.09759 \n",
      "Validation loss decreased (0.134956 --> 0.131342).  Saving model ...\n",
      "[ 81/200] train_loss: 0.11351 valid_loss: 0.13036 test_loss: 0.09664 \n",
      "Validation loss decreased (0.131342 --> 0.130358).  Saving model ...\n",
      "[ 82/200] train_loss: 0.11556 valid_loss: 0.13089 test_loss: 0.09842 \n",
      "[ 83/200] train_loss: 0.11293 valid_loss: 0.13415 test_loss: 0.09870 \n",
      "[ 84/200] train_loss: 0.11251 valid_loss: 0.13366 test_loss: 0.10077 \n",
      "[ 85/200] train_loss: 0.11578 valid_loss: 0.13160 test_loss: 0.09880 \n",
      "[ 86/200] train_loss: 0.11318 valid_loss: 0.13215 test_loss: 0.09884 \n",
      "[ 87/200] train_loss: 0.11236 valid_loss: 0.13233 test_loss: 0.09815 \n",
      "[ 88/200] train_loss: 0.11184 valid_loss: 0.13080 test_loss: 0.09794 \n",
      "[ 89/200] train_loss: 0.11011 valid_loss: 0.12968 test_loss: 0.09672 \n",
      "Validation loss decreased (0.130358 --> 0.129679).  Saving model ...\n",
      "[ 90/200] train_loss: 0.11161 valid_loss: 0.13286 test_loss: 0.09976 \n",
      "[ 91/200] train_loss: 0.10995 valid_loss: 0.13010 test_loss: 0.09776 \n",
      "[ 92/200] train_loss: 0.11216 valid_loss: 0.12966 test_loss: 0.09653 \n",
      "Validation loss decreased (0.129679 --> 0.129658).  Saving model ...\n",
      "[ 93/200] train_loss: 0.11223 valid_loss: 0.13078 test_loss: 0.09834 \n",
      "[ 94/200] train_loss: 0.11093 valid_loss: 0.12734 test_loss: 0.09583 \n",
      "Validation loss decreased (0.129658 --> 0.127342).  Saving model ...\n",
      "[ 95/200] train_loss: 0.10904 valid_loss: 0.12774 test_loss: 0.09418 \n",
      "[ 96/200] train_loss: 0.10978 valid_loss: 0.12955 test_loss: 0.09805 \n",
      "[ 97/200] train_loss: 0.11164 valid_loss: 0.13046 test_loss: 0.09755 \n",
      "[ 98/200] train_loss: 0.11015 valid_loss: 0.12870 test_loss: 0.09580 \n",
      "[ 99/200] train_loss: 0.10788 valid_loss: 0.12752 test_loss: 0.09480 \n",
      "[100/200] train_loss: 0.11368 valid_loss: 0.12752 test_loss: 0.09516 \n",
      "[101/200] train_loss: 0.10704 valid_loss: 0.12531 test_loss: 0.09258 \n",
      "Validation loss decreased (0.127342 --> 0.125315).  Saving model ...\n",
      "[102/200] train_loss: 0.11227 valid_loss: 0.12519 test_loss: 0.09383 \n",
      "Validation loss decreased (0.125315 --> 0.125192).  Saving model ...\n",
      "[103/200] train_loss: 0.10856 valid_loss: 0.12632 test_loss: 0.09358 \n",
      "[104/200] train_loss: 0.10916 valid_loss: 0.12532 test_loss: 0.09375 \n",
      "[105/200] train_loss: 0.10865 valid_loss: 0.12350 test_loss: 0.09277 \n",
      "Validation loss decreased (0.125192 --> 0.123496).  Saving model ...\n",
      "[106/200] train_loss: 0.10829 valid_loss: 0.12651 test_loss: 0.09347 \n",
      "[107/200] train_loss: 0.11008 valid_loss: 0.12459 test_loss: 0.09298 \n",
      "[108/200] train_loss: 0.10965 valid_loss: 0.12430 test_loss: 0.09221 \n",
      "[109/200] train_loss: 0.11011 valid_loss: 0.12469 test_loss: 0.09357 \n",
      "[110/200] train_loss: 0.10835 valid_loss: 0.12427 test_loss: 0.09389 \n",
      "[111/200] train_loss: 0.10816 valid_loss: 0.12263 test_loss: 0.09274 \n",
      "Validation loss decreased (0.123496 --> 0.122633).  Saving model ...\n",
      "[112/200] train_loss: 0.10780 valid_loss: 0.12298 test_loss: 0.09226 \n",
      "[113/200] train_loss: 0.10627 valid_loss: 0.12241 test_loss: 0.09133 \n",
      "Validation loss decreased (0.122633 --> 0.122414).  Saving model ...\n",
      "[114/200] train_loss: 0.10613 valid_loss: 0.12363 test_loss: 0.09302 \n",
      "[115/200] train_loss: 0.10670 valid_loss: 0.12231 test_loss: 0.09293 \n",
      "Validation loss decreased (0.122414 --> 0.122309).  Saving model ...\n",
      "[116/200] train_loss: 0.10607 valid_loss: 0.12120 test_loss: 0.09199 \n",
      "Validation loss decreased (0.122309 --> 0.121199).  Saving model ...\n",
      "[117/200] train_loss: 0.10514 valid_loss: 0.12329 test_loss: 0.09270 \n",
      "[118/200] train_loss: 0.10459 valid_loss: 0.12219 test_loss: 0.09265 \n",
      "[119/200] train_loss: 0.10410 valid_loss: 0.12235 test_loss: 0.09375 \n",
      "[120/200] train_loss: 0.10602 valid_loss: 0.12123 test_loss: 0.09074 \n",
      "[121/200] train_loss: 0.10396 valid_loss: 0.12089 test_loss: 0.09066 \n",
      "Validation loss decreased (0.121199 --> 0.120892).  Saving model ...\n",
      "[122/200] train_loss: 0.10240 valid_loss: 0.12011 test_loss: 0.09053 \n",
      "Validation loss decreased (0.120892 --> 0.120113).  Saving model ...\n",
      "[123/200] train_loss: 0.10789 valid_loss: 0.12013 test_loss: 0.09075 \n",
      "[124/200] train_loss: 0.10577 valid_loss: 0.12188 test_loss: 0.09246 \n",
      "[125/200] train_loss: 0.09994 valid_loss: 0.11855 test_loss: 0.08864 \n",
      "Validation loss decreased (0.120113 --> 0.118546).  Saving model ...\n",
      "[126/200] train_loss: 0.10480 valid_loss: 0.12353 test_loss: 0.09512 \n",
      "[127/200] train_loss: 0.10629 valid_loss: 0.12360 test_loss: 0.09173 \n",
      "[128/200] train_loss: 0.10156 valid_loss: 0.12079 test_loss: 0.08991 \n",
      "[129/200] train_loss: 0.10321 valid_loss: 0.12011 test_loss: 0.08938 \n",
      "[130/200] train_loss: 0.10176 valid_loss: 0.11833 test_loss: 0.08685 \n",
      "Validation loss decreased (0.118546 --> 0.118330).  Saving model ...\n",
      "[131/200] train_loss: 0.10424 valid_loss: 0.12252 test_loss: 0.09290 \n",
      "[132/200] train_loss: 0.10367 valid_loss: 0.12036 test_loss: 0.09082 \n",
      "[133/200] train_loss: 0.10283 valid_loss: 0.11965 test_loss: 0.09143 \n",
      "[134/200] train_loss: 0.10152 valid_loss: 0.11886 test_loss: 0.09085 \n",
      "[135/200] train_loss: 0.10037 valid_loss: 0.11909 test_loss: 0.08909 \n",
      "[136/200] train_loss: 0.09960 valid_loss: 0.11678 test_loss: 0.08805 \n",
      "Validation loss decreased (0.118330 --> 0.116784).  Saving model ...\n",
      "[137/200] train_loss: 0.10056 valid_loss: 0.11838 test_loss: 0.08977 \n",
      "[138/200] train_loss: 0.10037 valid_loss: 0.12017 test_loss: 0.09354 \n",
      "[139/200] train_loss: 0.09915 valid_loss: 0.11666 test_loss: 0.08831 \n",
      "Validation loss decreased (0.116784 --> 0.116664).  Saving model ...\n",
      "[140/200] train_loss: 0.10092 valid_loss: 0.11914 test_loss: 0.09053 \n",
      "[141/200] train_loss: 0.10057 valid_loss: 0.11769 test_loss: 0.09059 \n",
      "[142/200] train_loss: 0.10060 valid_loss: 0.11614 test_loss: 0.08794 \n",
      "Validation loss decreased (0.116664 --> 0.116137).  Saving model ...\n",
      "[143/200] train_loss: 0.10052 valid_loss: 0.11748 test_loss: 0.08941 \n",
      "[144/200] train_loss: 0.09939 valid_loss: 0.11635 test_loss: 0.08675 \n",
      "[145/200] train_loss: 0.09720 valid_loss: 0.11645 test_loss: 0.08938 \n",
      "[146/200] train_loss: 0.10307 valid_loss: 0.11820 test_loss: 0.09013 \n",
      "[147/200] train_loss: 0.10177 valid_loss: 0.11519 test_loss: 0.08739 \n",
      "Validation loss decreased (0.116137 --> 0.115193).  Saving model ...\n",
      "[148/200] train_loss: 0.09886 valid_loss: 0.11480 test_loss: 0.08802 \n",
      "Validation loss decreased (0.115193 --> 0.114798).  Saving model ...\n",
      "[149/200] train_loss: 0.10007 valid_loss: 0.11600 test_loss: 0.08811 \n",
      "[150/200] train_loss: 0.09691 valid_loss: 0.11534 test_loss: 0.08794 \n",
      "[151/200] train_loss: 0.09962 valid_loss: 0.11515 test_loss: 0.08759 \n",
      "[152/200] train_loss: 0.09713 valid_loss: 0.11345 test_loss: 0.08414 \n",
      "Validation loss decreased (0.114798 --> 0.113450).  Saving model ...\n",
      "[153/200] train_loss: 0.10029 valid_loss: 0.11758 test_loss: 0.08886 \n",
      "[154/200] train_loss: 0.09575 valid_loss: 0.11417 test_loss: 0.08725 \n",
      "[155/200] train_loss: 0.09891 valid_loss: 0.11505 test_loss: 0.08668 \n",
      "[156/200] train_loss: 0.09832 valid_loss: 0.11641 test_loss: 0.08870 \n",
      "[157/200] train_loss: 0.09667 valid_loss: 0.11496 test_loss: 0.08694 \n",
      "[158/200] train_loss: 0.10030 valid_loss: 0.11298 test_loss: 0.08442 \n",
      "Validation loss decreased (0.113450 --> 0.112978).  Saving model ...\n",
      "[159/200] train_loss: 0.09945 valid_loss: 0.11458 test_loss: 0.08421 \n",
      "[160/200] train_loss: 0.09859 valid_loss: 0.11176 test_loss: 0.08416 \n",
      "Validation loss decreased (0.112978 --> 0.111764).  Saving model ...\n",
      "[161/200] train_loss: 0.09767 valid_loss: 0.11246 test_loss: 0.08411 \n",
      "[162/200] train_loss: 0.09675 valid_loss: 0.11397 test_loss: 0.08718 \n",
      "[163/200] train_loss: 0.09761 valid_loss: 0.11595 test_loss: 0.08810 \n",
      "[164/200] train_loss: 0.09940 valid_loss: 0.11358 test_loss: 0.08625 \n",
      "[165/200] train_loss: 0.09613 valid_loss: 0.11359 test_loss: 0.08641 \n",
      "[166/200] train_loss: 0.09787 valid_loss: 0.11348 test_loss: 0.08828 \n",
      "[167/200] train_loss: 0.09625 valid_loss: 0.11379 test_loss: 0.08797 \n",
      "[168/200] train_loss: 0.09747 valid_loss: 0.11340 test_loss: 0.08540 \n",
      "[169/200] train_loss: 0.09520 valid_loss: 0.11210 test_loss: 0.08475 \n",
      "[170/200] train_loss: 0.09974 valid_loss: 0.11207 test_loss: 0.08692 \n",
      "[171/200] train_loss: 0.09774 valid_loss: 0.11260 test_loss: 0.08695 \n",
      "[172/200] train_loss: 0.09416 valid_loss: 0.11181 test_loss: 0.08612 \n",
      "[173/200] train_loss: 0.09582 valid_loss: 0.11324 test_loss: 0.08835 \n",
      "[174/200] train_loss: 0.09636 valid_loss: 0.11332 test_loss: 0.08705 \n",
      "[175/200] train_loss: 0.09416 valid_loss: 0.11279 test_loss: 0.08673 \n",
      "[176/200] train_loss: 0.09683 valid_loss: 0.11310 test_loss: 0.08702 \n",
      "[177/200] train_loss: 0.09615 valid_loss: 0.11246 test_loss: 0.08624 \n",
      "[178/200] train_loss: 0.09504 valid_loss: 0.11460 test_loss: 0.09042 \n",
      "[179/200] train_loss: 0.09651 valid_loss: 0.11229 test_loss: 0.08555 \n",
      "[180/200] train_loss: 0.09487 valid_loss: 0.11027 test_loss: 0.08334 \n",
      "Validation loss decreased (0.111764 --> 0.110269).  Saving model ...\n",
      "[181/200] train_loss: 0.09485 valid_loss: 0.11188 test_loss: 0.08425 \n",
      "[182/200] train_loss: 0.09414 valid_loss: 0.11176 test_loss: 0.08689 \n",
      "[183/200] train_loss: 0.09631 valid_loss: 0.11010 test_loss: 0.08546 \n",
      "Validation loss decreased (0.110269 --> 0.110098).  Saving model ...\n",
      "[184/200] train_loss: 0.09362 valid_loss: 0.11032 test_loss: 0.08518 \n",
      "[185/200] train_loss: 0.09182 valid_loss: 0.11098 test_loss: 0.08400 \n",
      "[186/200] train_loss: 0.09242 valid_loss: 0.11003 test_loss: 0.08586 \n",
      "Validation loss decreased (0.110098 --> 0.110029).  Saving model ...\n",
      "[187/200] train_loss: 0.09426 valid_loss: 0.11100 test_loss: 0.08631 \n",
      "[188/200] train_loss: 0.09347 valid_loss: 0.11053 test_loss: 0.08593 \n",
      "[189/200] train_loss: 0.09215 valid_loss: 0.10935 test_loss: 0.08540 \n",
      "Validation loss decreased (0.110029 --> 0.109350).  Saving model ...\n",
      "[190/200] train_loss: 0.09629 valid_loss: 0.11073 test_loss: 0.08545 \n",
      "[191/200] train_loss: 0.09289 valid_loss: 0.11207 test_loss: 0.08614 \n",
      "[192/200] train_loss: 0.09614 valid_loss: 0.11129 test_loss: 0.08637 \n",
      "[193/200] train_loss: 0.09221 valid_loss: 0.10809 test_loss: 0.08261 \n",
      "Validation loss decreased (0.109350 --> 0.108087).  Saving model ...\n",
      "[194/200] train_loss: 0.09523 valid_loss: 0.10936 test_loss: 0.08468 \n",
      "[195/200] train_loss: 0.09516 valid_loss: 0.11213 test_loss: 0.08680 \n",
      "[196/200] train_loss: 0.09277 valid_loss: 0.11092 test_loss: 0.08588 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils.net import PTPNet\n",
    "from utils.training import train_model\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "n_epochs = 200\n",
    "\n",
    "train_loader = dl_train\n",
    "valid_loader = dl_valid\n",
    "test_loader = dl_test\n",
    "model = PTPNet(1,3,32).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5.E-5)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([1.0, 0.9, 0.9])).cuda()\n",
    "fn='../data/ukdale/network_weights/UKDALE_network_weights.pth'\n",
    "model, train_loss, valid_loss, test_loss = train_model(model, batch_size, n_epochs, fn, train_loader, valid_loader, test_loader, optimizer, criterion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cac8f1-b7b1-4e0c-996e-c49a672e5932",
   "metadata": {},
   "source": [
    "# REFIT training network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a85407-aa8c-47d2-9717-7cd596c1579b",
   "metadata": {},
   "source": [
    "## Fridge case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f3726e-9dc1-4e33-9020-3a95333eb3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE = ['fridge']\n",
    "THRESHOLD = [20.]\n",
    "MIN_ON = [600. / 60]\n",
    "MIN_OFF = [100. / 60]\n",
    "\n",
    "METER = 'aggregate'\n",
    "SEQ_LEN = 60*8\n",
    "BORDER = 16\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "MAX_POWER = 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b8dee4-cd29-47be-913e-2039a4d93d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import get_status\n",
    "original_meter = []\n",
    "ds_appliance = []\n",
    "ds_status = []\n",
    "houses=[2,5,9,12,15]\n",
    "for i in houses:\n",
    "    ds = pd.read_feather('../data/refit/feather_files/fridge/REFIT_%d.feather' %i)\n",
    "    ds.set_index('datetime', inplace=True)\n",
    "    \n",
    "    meter = ds[METER]\n",
    "    appliances = ds[APPLIANCE]\n",
    "    \n",
    "    status = pd.DataFrame()\n",
    "    for a in range(len(APPLIANCE)):\n",
    "        status = pd.concat([status, get_status(ds[APPLIANCE[a]], THRESHOLD[a], MIN_OFF[a], MIN_ON[a])], axis=1)\n",
    "    \n",
    "    original_meter.append(meter)\n",
    "    ds_appliance.append(appliances)\n",
    "    ds_status.append(status)\n",
    "\n",
    "ds_len = [len(original_meter[i]) for i in range(len(houses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1210c891-39d9-4b45-a69e-154fd67c2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.preprocessing import Power\n",
    "\n",
    "ds_house_total  = [Power(original_meter[i], ds_appliance[i], ds_status[i],SEQ_LEN, BORDER, MAX_POWER, False) for i in range(len(houses))]\n",
    "ds_house_train  = [Power(original_meter[i][:int(0.8*ds_len[i])], \n",
    "                         ds_appliance[i][:int(0.8*ds_len[i])], \n",
    "                         ds_status[i][:int(0.8*ds_len[i])],\n",
    "                         SEQ_LEN, BORDER, MAX_POWER, True) for i in range(len(houses))]\n",
    "ds_house_valid  = [Power(original_meter[i][int(0.8*ds_len[i]):], \n",
    "                         ds_appliance[i][int(0.8*ds_len[i]):], \n",
    "                         ds_status[i][int(0.8*ds_len[i]):],\n",
    "                         SEQ_LEN, BORDER, MAX_POWER, False) for i in range(len(houses))]\n",
    "\n",
    "ds_train      = torch.utils.data.ConcatDataset([ds_house_train[i] for i in range(len(houses)-1)])\n",
    "ds_valid      = torch.utils.data.ConcatDataset([ds_house_valid[i] for i in range(len(houses)-1)])\n",
    "\n",
    "dl_train = DataLoader(dataset = ds_train, batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "dl_valid = DataLoader(dataset = ds_valid, batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "dl_test = DataLoader(dataset = ds_house_total[-1], batch_size = BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "067a4125-0716-48ba-988b-c5a702ff2b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/200] train_loss: 0.79067 valid_loss: 0.74895 test_loss: 0.71022 \n",
      "Validation loss decreased (inf --> 0.748947).  Saving model ...\n",
      "[  2/200] train_loss: 0.74336 valid_loss: 0.73062 test_loss: 0.66869 \n",
      "Validation loss decreased (0.748947 --> 0.730620).  Saving model ...\n",
      "[  3/200] train_loss: 0.70634 valid_loss: 0.66657 test_loss: 0.62075 \n",
      "Validation loss decreased (0.730620 --> 0.666571).  Saving model ...\n",
      "[  4/200] train_loss: 0.66884 valid_loss: 0.67297 test_loss: 0.61870 \n",
      "[  5/200] train_loss: 0.64395 valid_loss: 0.64848 test_loss: 0.56347 \n",
      "Validation loss decreased (0.666571 --> 0.648484).  Saving model ...\n",
      "[  6/200] train_loss: 0.63165 valid_loss: 0.69651 test_loss: 0.61628 \n",
      "[  7/200] train_loss: 0.62136 valid_loss: 0.67472 test_loss: 0.59341 \n",
      "[  8/200] train_loss: 0.61342 valid_loss: 0.61578 test_loss: 0.51655 \n",
      "Validation loss decreased (0.648484 --> 0.615778).  Saving model ...\n",
      "[  9/200] train_loss: 0.59939 valid_loss: 0.63544 test_loss: 0.53530 \n",
      "[ 10/200] train_loss: 0.60115 valid_loss: 0.64064 test_loss: 0.53025 \n",
      "[ 11/200] train_loss: 0.59580 valid_loss: 0.61827 test_loss: 0.51119 \n",
      "[ 12/200] train_loss: 0.59427 valid_loss: 0.61368 test_loss: 0.50891 \n",
      "Validation loss decreased (0.615778 --> 0.613684).  Saving model ...\n",
      "[ 13/200] train_loss: 0.58056 valid_loss: 0.57008 test_loss: 0.46643 \n",
      "Validation loss decreased (0.613684 --> 0.570084).  Saving model ...\n",
      "[ 14/200] train_loss: 0.57370 valid_loss: 0.62967 test_loss: 0.49892 \n",
      "[ 15/200] train_loss: 0.57173 valid_loss: 0.61516 test_loss: 0.50288 \n",
      "[ 16/200] train_loss: 0.56486 valid_loss: 0.56940 test_loss: 0.47212 \n",
      "Validation loss decreased (0.570084 --> 0.569402).  Saving model ...\n",
      "[ 17/200] train_loss: 0.55855 valid_loss: 0.54341 test_loss: 0.44539 \n",
      "Validation loss decreased (0.569402 --> 0.543408).  Saving model ...\n",
      "[ 18/200] train_loss: 0.55429 valid_loss: 0.53308 test_loss: 0.44158 \n",
      "Validation loss decreased (0.543408 --> 0.533081).  Saving model ...\n",
      "[ 19/200] train_loss: 0.54461 valid_loss: 0.52329 test_loss: 0.43671 \n",
      "Validation loss decreased (0.533081 --> 0.523287).  Saving model ...\n",
      "[ 20/200] train_loss: 0.55014 valid_loss: 0.52025 test_loss: 0.43694 \n",
      "Validation loss decreased (0.523287 --> 0.520247).  Saving model ...\n",
      "[ 21/200] train_loss: 0.54870 valid_loss: 0.50905 test_loss: 0.44672 \n",
      "Validation loss decreased (0.520247 --> 0.509053).  Saving model ...\n",
      "[ 22/200] train_loss: 0.54502 valid_loss: 0.49882 test_loss: 0.43431 \n",
      "Validation loss decreased (0.509053 --> 0.498820).  Saving model ...\n",
      "[ 23/200] train_loss: 0.53837 valid_loss: 0.49569 test_loss: 0.42654 \n",
      "Validation loss decreased (0.498820 --> 0.495688).  Saving model ...\n",
      "[ 24/200] train_loss: 0.53354 valid_loss: 0.49653 test_loss: 0.42653 \n",
      "[ 25/200] train_loss: 0.53686 valid_loss: 0.49958 test_loss: 0.49075 \n",
      "[ 26/200] train_loss: 0.52734 valid_loss: 0.49577 test_loss: 0.45108 \n",
      "[ 27/200] train_loss: 0.53191 valid_loss: 0.48201 test_loss: 0.44165 \n",
      "Validation loss decreased (0.495688 --> 0.482006).  Saving model ...\n",
      "[ 28/200] train_loss: 0.52857 valid_loss: 0.48226 test_loss: 0.43174 \n",
      "[ 29/200] train_loss: 0.52441 valid_loss: 0.51012 test_loss: 0.43723 \n",
      "[ 30/200] train_loss: 0.51508 valid_loss: 0.48251 test_loss: 0.40347 \n",
      "[ 31/200] train_loss: 0.51153 valid_loss: 0.49073 test_loss: 0.46981 \n",
      "[ 32/200] train_loss: 0.51441 valid_loss: 0.48031 test_loss: 0.43266 \n",
      "Validation loss decreased (0.482006 --> 0.480305).  Saving model ...\n",
      "[ 33/200] train_loss: 0.51585 valid_loss: 0.47997 test_loss: 0.42780 \n",
      "Validation loss decreased (0.480305 --> 0.479972).  Saving model ...\n",
      "[ 34/200] train_loss: 0.52008 valid_loss: 0.49093 test_loss: 0.41040 \n",
      "[ 35/200] train_loss: 0.51305 valid_loss: 0.48691 test_loss: 0.45378 \n",
      "[ 36/200] train_loss: 0.51148 valid_loss: 0.47137 test_loss: 0.43365 \n",
      "Validation loss decreased (0.479972 --> 0.471370).  Saving model ...\n",
      "[ 37/200] train_loss: 0.50825 valid_loss: 0.47810 test_loss: 0.45133 \n",
      "[ 38/200] train_loss: 0.50554 valid_loss: 0.48882 test_loss: 0.47807 \n",
      "[ 39/200] train_loss: 0.50494 valid_loss: 0.46801 test_loss: 0.43886 \n",
      "Validation loss decreased (0.471370 --> 0.468008).  Saving model ...\n",
      "[ 40/200] train_loss: 0.49831 valid_loss: 0.49574 test_loss: 0.41507 \n",
      "[ 41/200] train_loss: 0.50910 valid_loss: 0.46624 test_loss: 0.40246 \n",
      "Validation loss decreased (0.468008 --> 0.466243).  Saving model ...\n",
      "[ 42/200] train_loss: 0.50112 valid_loss: 0.47379 test_loss: 0.40241 \n",
      "[ 43/200] train_loss: 0.49104 valid_loss: 0.46986 test_loss: 0.41937 \n",
      "[ 44/200] train_loss: 0.49170 valid_loss: 0.47072 test_loss: 0.41862 \n",
      "[ 45/200] train_loss: 0.48547 valid_loss: 0.46578 test_loss: 0.38996 \n",
      "Validation loss decreased (0.466243 --> 0.465776).  Saving model ...\n",
      "[ 46/200] train_loss: 0.48748 valid_loss: 0.46159 test_loss: 0.41669 \n",
      "Validation loss decreased (0.465776 --> 0.461592).  Saving model ...\n",
      "[ 47/200] train_loss: 0.48574 valid_loss: 0.46199 test_loss: 0.41565 \n",
      "[ 48/200] train_loss: 0.49580 valid_loss: 0.45629 test_loss: 0.40385 \n",
      "Validation loss decreased (0.461592 --> 0.456292).  Saving model ...\n",
      "[ 49/200] train_loss: 0.48886 valid_loss: 0.46483 test_loss: 0.38885 \n",
      "[ 50/200] train_loss: 0.48476 valid_loss: 0.47616 test_loss: 0.42868 \n",
      "[ 51/200] train_loss: 0.48430 valid_loss: 0.45734 test_loss: 0.39036 \n",
      "[ 52/200] train_loss: 0.47493 valid_loss: 0.46157 test_loss: 0.47287 \n",
      "[ 53/200] train_loss: 0.48467 valid_loss: 0.46410 test_loss: 0.42433 \n",
      "[ 54/200] train_loss: 0.47874 valid_loss: 0.46289 test_loss: 0.44251 \n",
      "[ 55/200] train_loss: 0.46898 valid_loss: 0.46931 test_loss: 0.40606 \n",
      "[ 56/200] train_loss: 0.47404 valid_loss: 0.46281 test_loss: 0.41541 \n",
      "[ 57/200] train_loss: 0.47254 valid_loss: 0.45776 test_loss: 0.39617 \n",
      "[ 58/200] train_loss: 0.47185 valid_loss: 0.46497 test_loss: 0.40746 \n",
      "[ 59/200] train_loss: 0.47059 valid_loss: 0.48811 test_loss: 0.47983 \n",
      "[ 60/200] train_loss: 0.46968 valid_loss: 0.45754 test_loss: 0.37765 \n",
      "[ 61/200] train_loss: 0.46792 valid_loss: 0.46532 test_loss: 0.44595 \n",
      "[ 62/200] train_loss: 0.46703 valid_loss: 0.45382 test_loss: 0.38523 \n",
      "Validation loss decreased (0.456292 --> 0.453822).  Saving model ...\n",
      "[ 63/200] train_loss: 0.46929 valid_loss: 0.45051 test_loss: 0.37080 \n",
      "Validation loss decreased (0.453822 --> 0.450514).  Saving model ...\n",
      "[ 64/200] train_loss: 0.47788 valid_loss: 0.46308 test_loss: 0.37879 \n",
      "[ 65/200] train_loss: 0.47020 valid_loss: 0.46401 test_loss: 0.40492 \n",
      "[ 66/200] train_loss: 0.46425 valid_loss: 0.45654 test_loss: 0.36558 \n",
      "[ 67/200] train_loss: 0.45889 valid_loss: 0.45757 test_loss: 0.38688 \n",
      "[ 68/200] train_loss: 0.46584 valid_loss: 0.45183 test_loss: 0.39735 \n",
      "[ 69/200] train_loss: 0.46619 valid_loss: 0.43871 test_loss: 0.36394 \n",
      "Validation loss decreased (0.450514 --> 0.438706).  Saving model ...\n",
      "[ 70/200] train_loss: 0.46293 valid_loss: 0.44456 test_loss: 0.35069 \n",
      "[ 71/200] train_loss: 0.46704 valid_loss: 0.46339 test_loss: 0.37382 \n",
      "[ 72/200] train_loss: 0.46237 valid_loss: 0.45616 test_loss: 0.39939 \n",
      "[ 73/200] train_loss: 0.46381 valid_loss: 0.45820 test_loss: 0.36775 \n",
      "[ 74/200] train_loss: 0.47124 valid_loss: 0.45285 test_loss: 0.35046 \n",
      "[ 75/200] train_loss: 0.45682 valid_loss: 0.47612 test_loss: 0.36539 \n",
      "[ 76/200] train_loss: 0.45194 valid_loss: 0.50373 test_loss: 0.37431 \n",
      "[ 77/200] train_loss: 0.45069 valid_loss: 0.44583 test_loss: 0.35241 \n",
      "[ 78/200] train_loss: 0.45742 valid_loss: 0.44366 test_loss: 0.35286 \n",
      "[ 79/200] train_loss: 0.45294 valid_loss: 0.44852 test_loss: 0.35107 \n",
      "[ 80/200] train_loss: 0.44136 valid_loss: 0.44693 test_loss: 0.35595 \n",
      "[ 81/200] train_loss: 0.45272 valid_loss: 0.45157 test_loss: 0.34758 \n",
      "[ 82/200] train_loss: 0.44142 valid_loss: 0.43765 test_loss: 0.35920 \n",
      "Validation loss decreased (0.438706 --> 0.437654).  Saving model ...\n",
      "[ 83/200] train_loss: 0.44986 valid_loss: 0.44561 test_loss: 0.35520 \n",
      "[ 84/200] train_loss: 0.45039 valid_loss: 0.47722 test_loss: 0.37317 \n",
      "[ 85/200] train_loss: 0.45351 valid_loss: 0.44634 test_loss: 0.34995 \n",
      "[ 86/200] train_loss: 0.44460 valid_loss: 0.45019 test_loss: 0.37169 \n",
      "[ 87/200] train_loss: 0.45166 valid_loss: 0.46775 test_loss: 0.34577 \n",
      "[ 88/200] train_loss: 0.44825 valid_loss: 0.45567 test_loss: 0.36046 \n",
      "[ 89/200] train_loss: 0.43824 valid_loss: 0.46974 test_loss: 0.35129 \n",
      "[ 90/200] train_loss: 0.44126 valid_loss: 0.45059 test_loss: 0.34678 \n",
      "[ 91/200] train_loss: 0.43557 valid_loss: 0.47252 test_loss: 0.34384 \n",
      "[ 92/200] train_loss: 0.44760 valid_loss: 0.46622 test_loss: 0.35791 \n",
      "[ 93/200] train_loss: 0.44046 valid_loss: 0.44339 test_loss: 0.36771 \n",
      "[ 94/200] train_loss: 0.43556 valid_loss: 0.48183 test_loss: 0.35949 \n",
      "[ 95/200] train_loss: 0.44818 valid_loss: 0.44247 test_loss: 0.34439 \n",
      "[ 96/200] train_loss: 0.43950 valid_loss: 0.44443 test_loss: 0.33975 \n",
      "[ 97/200] train_loss: 0.44356 valid_loss: 0.46490 test_loss: 0.34582 \n",
      "[ 98/200] train_loss: 0.44001 valid_loss: 0.45708 test_loss: 0.34676 \n",
      "[ 99/200] train_loss: 0.43984 valid_loss: 0.43997 test_loss: 0.33877 \n",
      "[100/200] train_loss: 0.44190 valid_loss: 0.49304 test_loss: 0.36601 \n",
      "[101/200] train_loss: 0.43957 valid_loss: 0.45090 test_loss: 0.34147 \n",
      "[102/200] train_loss: 0.43224 valid_loss: 0.44397 test_loss: 0.34565 \n",
      "[103/200] train_loss: 0.42750 valid_loss: 0.43718 test_loss: 0.35380 \n",
      "Validation loss decreased (0.437654 --> 0.437176).  Saving model ...\n",
      "[104/200] train_loss: 0.43547 valid_loss: 0.44494 test_loss: 0.35538 \n",
      "[105/200] train_loss: 0.43610 valid_loss: 0.44875 test_loss: 0.36403 \n",
      "[106/200] train_loss: 0.43114 valid_loss: 0.44480 test_loss: 0.33794 \n",
      "[107/200] train_loss: 0.43524 valid_loss: 0.44674 test_loss: 0.34024 \n",
      "[108/200] train_loss: 0.42536 valid_loss: 0.44816 test_loss: 0.33364 \n",
      "[109/200] train_loss: 0.42456 valid_loss: 0.44007 test_loss: 0.34484 \n",
      "[110/200] train_loss: 0.43375 valid_loss: 0.43970 test_loss: 0.34205 \n",
      "[111/200] train_loss: 0.42449 valid_loss: 0.43941 test_loss: 0.33873 \n",
      "[112/200] train_loss: 0.42144 valid_loss: 0.44047 test_loss: 0.32498 \n",
      "[113/200] train_loss: 0.42710 valid_loss: 0.48515 test_loss: 0.34950 \n",
      "[114/200] train_loss: 0.42974 valid_loss: 0.44424 test_loss: 0.33504 \n",
      "[115/200] train_loss: 0.42511 valid_loss: 0.45788 test_loss: 0.32996 \n",
      "[116/200] train_loss: 0.42847 valid_loss: 0.43881 test_loss: 0.32736 \n",
      "[117/200] train_loss: 0.43199 valid_loss: 0.43945 test_loss: 0.32693 \n",
      "[118/200] train_loss: 0.43753 valid_loss: 0.45269 test_loss: 0.33549 \n",
      "[119/200] train_loss: 0.42961 valid_loss: 0.46999 test_loss: 0.32945 \n",
      "[120/200] train_loss: 0.42543 valid_loss: 0.45668 test_loss: 0.33309 \n",
      "[121/200] train_loss: 0.42851 valid_loss: 0.46816 test_loss: 0.33005 \n",
      "[122/200] train_loss: 0.42320 valid_loss: 0.47863 test_loss: 0.34201 \n",
      "[123/200] train_loss: 0.41850 valid_loss: 0.45727 test_loss: 0.32794 \n",
      "[124/200] train_loss: 0.42374 valid_loss: 0.44710 test_loss: 0.32335 \n",
      "[125/200] train_loss: 0.42178 valid_loss: 0.45114 test_loss: 0.33748 \n",
      "[126/200] train_loss: 0.42752 valid_loss: 0.44181 test_loss: 0.32288 \n",
      "[127/200] train_loss: 0.42828 valid_loss: 0.42744 test_loss: 0.32071 \n",
      "Validation loss decreased (0.437176 --> 0.427441).  Saving model ...\n",
      "[128/200] train_loss: 0.41939 valid_loss: 0.44092 test_loss: 0.33217 \n",
      "[129/200] train_loss: 0.41971 valid_loss: 0.44968 test_loss: 0.32097 \n",
      "[130/200] train_loss: 0.42626 valid_loss: 0.46919 test_loss: 0.32951 \n",
      "[131/200] train_loss: 0.41815 valid_loss: 0.44823 test_loss: 0.33771 \n",
      "[132/200] train_loss: 0.42509 valid_loss: 0.42599 test_loss: 0.32373 \n",
      "Validation loss decreased (0.427441 --> 0.425988).  Saving model ...\n",
      "[133/200] train_loss: 0.41926 valid_loss: 0.44602 test_loss: 0.33171 \n",
      "[134/200] train_loss: 0.41844 valid_loss: 0.47988 test_loss: 0.32697 \n",
      "[135/200] train_loss: 0.41687 valid_loss: 0.45761 test_loss: 0.32915 \n",
      "[136/200] train_loss: 0.42222 valid_loss: 0.44720 test_loss: 0.33920 \n",
      "[137/200] train_loss: 0.42147 valid_loss: 0.44740 test_loss: 0.32745 \n",
      "[138/200] train_loss: 0.41966 valid_loss: 0.44402 test_loss: 0.32960 \n",
      "[139/200] train_loss: 0.41652 valid_loss: 0.43596 test_loss: 0.32606 \n",
      "[140/200] train_loss: 0.41804 valid_loss: 0.43794 test_loss: 0.33932 \n",
      "[141/200] train_loss: 0.40795 valid_loss: 0.44363 test_loss: 0.31825 \n",
      "[142/200] train_loss: 0.40996 valid_loss: 0.44580 test_loss: 0.32255 \n",
      "[143/200] train_loss: 0.41539 valid_loss: 0.47344 test_loss: 0.33771 \n",
      "[144/200] train_loss: 0.41654 valid_loss: 0.44768 test_loss: 0.31708 \n",
      "[145/200] train_loss: 0.41121 valid_loss: 0.52761 test_loss: 0.35151 \n",
      "[146/200] train_loss: 0.40769 valid_loss: 0.50031 test_loss: 0.34445 \n",
      "[147/200] train_loss: 0.41856 valid_loss: 0.47518 test_loss: 0.33687 \n",
      "[148/200] train_loss: 0.41064 valid_loss: 0.54271 test_loss: 0.36119 \n",
      "[149/200] train_loss: 0.41783 valid_loss: 0.45438 test_loss: 0.32300 \n",
      "[150/200] train_loss: 0.40607 valid_loss: 0.47488 test_loss: 0.32979 \n",
      "[151/200] train_loss: 0.41449 valid_loss: 0.44548 test_loss: 0.31330 \n",
      "[152/200] train_loss: 0.40617 valid_loss: 0.49152 test_loss: 0.33196 \n",
      "[153/200] train_loss: 0.40814 valid_loss: 0.47987 test_loss: 0.32960 \n",
      "[154/200] train_loss: 0.41484 valid_loss: 0.44380 test_loss: 0.32054 \n",
      "[155/200] train_loss: 0.41574 valid_loss: 0.47358 test_loss: 0.32944 \n",
      "[156/200] train_loss: 0.40819 valid_loss: 0.43285 test_loss: 0.31429 \n",
      "[157/200] train_loss: 0.40267 valid_loss: 0.46934 test_loss: 0.31939 \n",
      "[158/200] train_loss: 0.40873 valid_loss: 0.44748 test_loss: 0.31609 \n",
      "[159/200] train_loss: 0.40333 valid_loss: 0.50405 test_loss: 0.35000 \n",
      "[160/200] train_loss: 0.40789 valid_loss: 0.44290 test_loss: 0.31680 \n",
      "[161/200] train_loss: 0.40527 valid_loss: 0.51505 test_loss: 0.35058 \n",
      "[162/200] train_loss: 0.40933 valid_loss: 0.49781 test_loss: 0.34064 \n",
      "[163/200] train_loss: 0.40512 valid_loss: 0.46663 test_loss: 0.32008 \n",
      "[164/200] train_loss: 0.40709 valid_loss: 0.45426 test_loss: 0.32421 \n",
      "[165/200] train_loss: 0.39937 valid_loss: 0.45606 test_loss: 0.31907 \n",
      "[166/200] train_loss: 0.40098 valid_loss: 0.43253 test_loss: 0.31081 \n",
      "[167/200] train_loss: 0.40606 valid_loss: 0.46706 test_loss: 0.31567 \n",
      "[168/200] train_loss: 0.41004 valid_loss: 0.45499 test_loss: 0.32757 \n",
      "[169/200] train_loss: 0.40183 valid_loss: 0.43937 test_loss: 0.30806 \n",
      "[170/200] train_loss: 0.40150 valid_loss: 0.48779 test_loss: 0.34284 \n",
      "[171/200] train_loss: 0.40713 valid_loss: 0.44819 test_loss: 0.31417 \n",
      "[172/200] train_loss: 0.40261 valid_loss: 0.50956 test_loss: 0.34738 \n",
      "[173/200] train_loss: 0.40531 valid_loss: 0.44502 test_loss: 0.31633 \n",
      "[174/200] train_loss: 0.40506 valid_loss: 0.47644 test_loss: 0.33498 \n",
      "[175/200] train_loss: 0.40229 valid_loss: 0.57665 test_loss: 0.37468 \n",
      "[176/200] train_loss: 0.40804 valid_loss: 0.48137 test_loss: 0.33143 \n",
      "[177/200] train_loss: 0.40796 valid_loss: 0.51010 test_loss: 0.34213 \n",
      "[178/200] train_loss: 0.40027 valid_loss: 0.67162 test_loss: 0.42569 \n",
      "[179/200] train_loss: 0.40306 valid_loss: 0.49019 test_loss: 0.33061 \n",
      "[180/200] train_loss: 0.40056 valid_loss: 0.51378 test_loss: 0.34526 \n",
      "[181/200] train_loss: 0.40453 valid_loss: 0.46229 test_loss: 0.31972 \n",
      "[182/200] train_loss: 0.39381 valid_loss: 0.55063 test_loss: 0.36097 \n",
      "[183/200] train_loss: 0.38982 valid_loss: 0.44479 test_loss: 0.34773 \n",
      "[184/200] train_loss: 0.40148 valid_loss: 0.47853 test_loss: 0.33318 \n",
      "[185/200] train_loss: 0.38903 valid_loss: 0.44533 test_loss: 0.31098 \n",
      "[186/200] train_loss: 0.39644 valid_loss: 0.47930 test_loss: 0.32511 \n",
      "[187/200] train_loss: 0.39902 valid_loss: 0.52535 test_loss: 0.35380 \n",
      "[188/200] train_loss: 0.40944 valid_loss: 0.45798 test_loss: 0.31668 \n",
      "[189/200] train_loss: 0.39968 valid_loss: 0.49667 test_loss: 0.33365 \n",
      "[190/200] train_loss: 0.39146 valid_loss: 0.45081 test_loss: 0.31328 \n",
      "[191/200] train_loss: 0.39611 valid_loss: 0.51573 test_loss: 0.34234 \n",
      "[192/200] train_loss: 0.39542 valid_loss: 0.48091 test_loss: 0.31875 \n",
      "[193/200] train_loss: 0.40031 valid_loss: 0.49230 test_loss: 0.33753 \n",
      "[194/200] train_loss: 0.40332 valid_loss: 0.48645 test_loss: 0.32487 \n",
      "[195/200] train_loss: 0.39732 valid_loss: 0.53875 test_loss: 0.35954 \n",
      "[196/200] train_loss: 0.39927 valid_loss: 0.46530 test_loss: 0.31775 \n",
      "[197/200] train_loss: 0.39613 valid_loss: 0.45648 test_loss: 0.31711 \n",
      "[198/200] train_loss: 0.39554 valid_loss: 0.45444 test_loss: 0.32124 \n",
      "[199/200] train_loss: 0.39346 valid_loss: 0.46881 test_loss: 0.31624 \n",
      "[200/200] train_loss: 0.40005 valid_loss: 0.49063 test_loss: 0.31660 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils.net import PTPNet\n",
    "from utils.training import train_model\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "n_epochs = 200\n",
    "\n",
    "train_loader = dl_train\n",
    "valid_loader = dl_valid\n",
    "test_loader = dl_test\n",
    "\n",
    "model = PTPNet(1,1,32).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5.E-5)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([1.5])).cuda()\n",
    "fn = '../data/refit/network_weights/REFIT_fridge_network_weights.pth'\n",
    "model, train_loss, valid_loss, test_loss = train_model(model, batch_size, n_epochs, fn, train_loader, valid_loader, test_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fbe634-fca1-47aa-8ca3-46a220582dae",
   "metadata": {},
   "source": [
    "## Dishwasher case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfcb0c38-d8ff-4c3f-af11-00957bb64835",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE = ['dishwasher']\n",
    "THRESHOLD = [30.]\n",
    "MIN_ON = [1400. / 60]\n",
    "MIN_OFF = [1600. / 60]\n",
    "\n",
    "METER = 'aggregate'\n",
    "SEQ_LEN = 60*8\n",
    "BORDER = 16\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "MAX_POWER = 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49035a44-156d-49fe-a18c-57f909dde269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import get_status\n",
    "original_meter = []\n",
    "ds_appliance = []\n",
    "ds_status = []\n",
    "houses=[1,3,5,6,7,9,10,11,13,15,16,18,20,2]\n",
    "\n",
    "for i in houses:\n",
    "    ds = pd.read_feather('../data/refit/feather_files/dishwasher/REFIT_%d.feather' %i)\n",
    "    ds.set_index('datetime', inplace=True)\n",
    "    \n",
    "    meter = ds[METER]\n",
    "    appliances = ds[APPLIANCE]\n",
    "    \n",
    "    status = pd.DataFrame()\n",
    "    for a in range(len(APPLIANCE)):\n",
    "        status = pd.concat([status, get_status(ds[APPLIANCE[a]], THRESHOLD[a], MIN_OFF[a], MIN_ON[a])], axis=1)\n",
    "    \n",
    "    original_meter.append(meter)\n",
    "    ds_appliance.append(appliances)\n",
    "    ds_status.append(status)\n",
    "\n",
    "ds_len = [len(original_meter[i]) for i in range(len(houses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5142a81-8980-4e1b-a83b-a900467b94ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.preprocessing import Power\n",
    "\n",
    "ds_house_total  = [Power(original_meter[i], ds_appliance[i], ds_status[i],SEQ_LEN, BORDER, MAX_POWER, False) for i in range(len(houses))]\n",
    "ds_house_train  = [Power(original_meter[i][:int(0.8*ds_len[i])], \n",
    "                         ds_appliance[i][:int(0.8*ds_len[i])], \n",
    "                         ds_status[i][:int(0.8*ds_len[i])],\n",
    "                         SEQ_LEN, BORDER, MAX_POWER, True) for i in range(len(houses))]\n",
    "ds_house_valid  = [Power(original_meter[i][int(0.8*ds_len[i]):], \n",
    "                         ds_appliance[i][int(0.8*ds_len[i]):], \n",
    "                         ds_status[i][int(0.8*ds_len[i]):],\n",
    "                         SEQ_LEN, BORDER, MAX_POWER, False) for i in range(len(houses))]\n",
    "\n",
    "ds_train      = torch.utils.data.ConcatDataset([ds_house_train[i] for i in range(len(houses)-1)])\n",
    "ds_valid      = torch.utils.data.ConcatDataset([ds_house_valid[i] for i in range(len(houses)-1)])\n",
    "\n",
    "dl_train = DataLoader(dataset = ds_train, batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "dl_valid = DataLoader(dataset = ds_valid, batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "dl_test = DataLoader(dataset = ds_house_total[-1], batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "dl_house_total = [DataLoader(dataset = ds_house_total[i], batch_size = 1, shuffle=False) for i in range(len(houses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c95155d-2d79-45f1-8429-f29bea064164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/100] train_loss: 0.28475 valid_loss: 0.11968 test_loss: 0.20956 \n",
      "Validation loss decreased (inf --> 0.119684).  Saving model ...\n",
      "[  2/100] train_loss: 0.14600 valid_loss: 0.09399 test_loss: 0.17118 \n",
      "Validation loss decreased (0.119684 --> 0.093994).  Saving model ...\n",
      "[  3/100] train_loss: 0.13236 valid_loss: 0.08466 test_loss: 0.14345 \n",
      "Validation loss decreased (0.093994 --> 0.084663).  Saving model ...\n",
      "[  4/100] train_loss: 0.12355 valid_loss: 0.08342 test_loss: 0.13584 \n",
      "Validation loss decreased (0.084663 --> 0.083422).  Saving model ...\n",
      "[  5/100] train_loss: 0.12522 valid_loss: 0.08108 test_loss: 0.13313 \n",
      "Validation loss decreased (0.083422 --> 0.081081).  Saving model ...\n",
      "[  6/100] train_loss: 0.12170 valid_loss: 0.08034 test_loss: 0.12393 \n",
      "Validation loss decreased (0.081081 --> 0.080339).  Saving model ...\n",
      "[  7/100] train_loss: 0.11863 valid_loss: 0.07584 test_loss: 0.11985 \n",
      "Validation loss decreased (0.080339 --> 0.075841).  Saving model ...\n",
      "[  8/100] train_loss: 0.11050 valid_loss: 0.07297 test_loss: 0.11693 \n",
      "Validation loss decreased (0.075841 --> 0.072968).  Saving model ...\n",
      "[  9/100] train_loss: 0.11038 valid_loss: 0.07386 test_loss: 0.11232 \n",
      "[ 10/100] train_loss: 0.11170 valid_loss: 0.07343 test_loss: 0.11085 \n",
      "[ 11/100] train_loss: 0.11262 valid_loss: 0.07010 test_loss: 0.10737 \n",
      "Validation loss decreased (0.072968 --> 0.070097).  Saving model ...\n",
      "[ 12/100] train_loss: 0.10953 valid_loss: 0.07320 test_loss: 0.10946 \n",
      "[ 13/100] train_loss: 0.10440 valid_loss: 0.07170 test_loss: 0.10383 \n",
      "[ 14/100] train_loss: 0.10946 valid_loss: 0.07304 test_loss: 0.10574 \n",
      "[ 15/100] train_loss: 0.10998 valid_loss: 0.06702 test_loss: 0.10137 \n",
      "Validation loss decreased (0.070097 --> 0.067015).  Saving model ...\n",
      "[ 16/100] train_loss: 0.10859 valid_loss: 0.06943 test_loss: 0.10146 \n",
      "[ 17/100] train_loss: 0.10956 valid_loss: 0.06753 test_loss: 0.09821 \n",
      "[ 18/100] train_loss: 0.10614 valid_loss: 0.07066 test_loss: 0.09888 \n",
      "[ 19/100] train_loss: 0.10823 valid_loss: 0.06794 test_loss: 0.10078 \n",
      "[ 20/100] train_loss: 0.10948 valid_loss: 0.06979 test_loss: 0.09966 \n",
      "[ 21/100] train_loss: 0.10652 valid_loss: 0.06618 test_loss: 0.09652 \n",
      "Validation loss decreased (0.067015 --> 0.066179).  Saving model ...\n",
      "[ 22/100] train_loss: 0.10269 valid_loss: 0.07180 test_loss: 0.10172 \n",
      "[ 23/100] train_loss: 0.10010 valid_loss: 0.06553 test_loss: 0.09526 \n",
      "Validation loss decreased (0.066179 --> 0.065530).  Saving model ...\n",
      "[ 24/100] train_loss: 0.10053 valid_loss: 0.06955 test_loss: 0.09699 \n",
      "[ 25/100] train_loss: 0.10442 valid_loss: 0.06795 test_loss: 0.09602 \n",
      "[ 26/100] train_loss: 0.09444 valid_loss: 0.06743 test_loss: 0.09471 \n",
      "[ 27/100] train_loss: 0.09755 valid_loss: 0.06186 test_loss: 0.09042 \n",
      "Validation loss decreased (0.065530 --> 0.061857).  Saving model ...\n",
      "[ 28/100] train_loss: 0.09517 valid_loss: 0.06454 test_loss: 0.09156 \n",
      "[ 29/100] train_loss: 0.09719 valid_loss: 0.06034 test_loss: 0.08975 \n",
      "Validation loss decreased (0.061857 --> 0.060345).  Saving model ...\n",
      "[ 30/100] train_loss: 0.09473 valid_loss: 0.06740 test_loss: 0.09377 \n",
      "[ 31/100] train_loss: 0.09855 valid_loss: 0.06387 test_loss: 0.09459 \n",
      "[ 32/100] train_loss: 0.09027 valid_loss: 0.06405 test_loss: 0.08974 \n",
      "[ 33/100] train_loss: 0.08736 valid_loss: 0.06341 test_loss: 0.09250 \n",
      "[ 34/100] train_loss: 0.09258 valid_loss: 0.06547 test_loss: 0.09196 \n",
      "[ 35/100] train_loss: 0.09021 valid_loss: 0.06351 test_loss: 0.09007 \n",
      "[ 36/100] train_loss: 0.09517 valid_loss: 0.06519 test_loss: 0.09319 \n",
      "[ 37/100] train_loss: 0.09231 valid_loss: 0.06516 test_loss: 0.09086 \n",
      "[ 38/100] train_loss: 0.08505 valid_loss: 0.06101 test_loss: 0.08823 \n",
      "[ 39/100] train_loss: 0.09141 valid_loss: 0.06003 test_loss: 0.08907 \n",
      "Validation loss decreased (0.060345 --> 0.060033).  Saving model ...\n",
      "[ 40/100] train_loss: 0.08885 valid_loss: 0.06448 test_loss: 0.09211 \n",
      "[ 41/100] train_loss: 0.08964 valid_loss: 0.06159 test_loss: 0.09310 \n",
      "[ 42/100] train_loss: 0.08714 valid_loss: 0.06007 test_loss: 0.08780 \n",
      "[ 43/100] train_loss: 0.08488 valid_loss: 0.06400 test_loss: 0.09246 \n",
      "[ 44/100] train_loss: 0.08469 valid_loss: 0.05998 test_loss: 0.08674 \n",
      "Validation loss decreased (0.060033 --> 0.059982).  Saving model ...\n",
      "[ 45/100] train_loss: 0.08001 valid_loss: 0.06206 test_loss: 0.08820 \n",
      "[ 46/100] train_loss: 0.08329 valid_loss: 0.06107 test_loss: 0.08917 \n",
      "[ 47/100] train_loss: 0.08753 valid_loss: 0.06444 test_loss: 0.08941 \n",
      "[ 48/100] train_loss: 0.08659 valid_loss: 0.06082 test_loss: 0.08554 \n",
      "[ 49/100] train_loss: 0.08515 valid_loss: 0.06754 test_loss: 0.09438 \n",
      "[ 50/100] train_loss: 0.08423 valid_loss: 0.06194 test_loss: 0.09082 \n",
      "[ 51/100] train_loss: 0.07871 valid_loss: 0.06004 test_loss: 0.08601 \n",
      "[ 52/100] train_loss: 0.07915 valid_loss: 0.05803 test_loss: 0.08941 \n",
      "Validation loss decreased (0.059982 --> 0.058034).  Saving model ...\n",
      "[ 53/100] train_loss: 0.07975 valid_loss: 0.05871 test_loss: 0.08711 \n",
      "[ 54/100] train_loss: 0.08178 valid_loss: 0.06013 test_loss: 0.09638 \n",
      "[ 55/100] train_loss: 0.07508 valid_loss: 0.06506 test_loss: 0.09368 \n",
      "[ 56/100] train_loss: 0.08216 valid_loss: 0.06040 test_loss: 0.09248 \n",
      "[ 57/100] train_loss: 0.07632 valid_loss: 0.06066 test_loss: 0.08880 \n",
      "[ 58/100] train_loss: 0.07707 valid_loss: 0.05785 test_loss: 0.08890 \n",
      "Validation loss decreased (0.058034 --> 0.057854).  Saving model ...\n",
      "[ 59/100] train_loss: 0.07489 valid_loss: 0.06208 test_loss: 0.09031 \n",
      "[ 60/100] train_loss: 0.07793 valid_loss: 0.06171 test_loss: 0.09071 \n",
      "[ 61/100] train_loss: 0.07544 valid_loss: 0.06087 test_loss: 0.08845 \n",
      "[ 62/100] train_loss: 0.07374 valid_loss: 0.06107 test_loss: 0.09110 \n",
      "[ 63/100] train_loss: 0.08019 valid_loss: 0.06525 test_loss: 0.08780 \n",
      "[ 64/100] train_loss: 0.07856 valid_loss: 0.05919 test_loss: 0.08949 \n",
      "[ 65/100] train_loss: 0.07869 valid_loss: 0.06068 test_loss: 0.08935 \n",
      "[ 66/100] train_loss: 0.07840 valid_loss: 0.06098 test_loss: 0.09081 \n",
      "[ 67/100] train_loss: 0.07200 valid_loss: 0.06333 test_loss: 0.09117 \n",
      "[ 68/100] train_loss: 0.07682 valid_loss: 0.06391 test_loss: 0.09408 \n",
      "[ 69/100] train_loss: 0.07184 valid_loss: 0.06170 test_loss: 0.09036 \n",
      "[ 70/100] train_loss: 0.07575 valid_loss: 0.05877 test_loss: 0.08765 \n",
      "[ 71/100] train_loss: 0.07709 valid_loss: 0.06717 test_loss: 0.09607 \n",
      "[ 72/100] train_loss: 0.07507 valid_loss: 0.06489 test_loss: 0.09739 \n",
      "[ 73/100] train_loss: 0.06972 valid_loss: 0.05934 test_loss: 0.08723 \n",
      "[ 74/100] train_loss: 0.07252 valid_loss: 0.06314 test_loss: 0.09182 \n",
      "[ 75/100] train_loss: 0.07399 valid_loss: 0.06146 test_loss: 0.09187 \n",
      "[ 76/100] train_loss: 0.07259 valid_loss: 0.06091 test_loss: 0.08558 \n",
      "[ 77/100] train_loss: 0.07140 valid_loss: 0.06679 test_loss: 0.10063 \n",
      "[ 78/100] train_loss: 0.07344 valid_loss: 0.06261 test_loss: 0.08714 \n",
      "[ 79/100] train_loss: 0.07145 valid_loss: 0.06321 test_loss: 0.09155 \n",
      "[ 80/100] train_loss: 0.06891 valid_loss: 0.06439 test_loss: 0.09632 \n",
      "[ 81/100] train_loss: 0.06571 valid_loss: 0.06131 test_loss: 0.08954 \n",
      "[ 82/100] train_loss: 0.07016 valid_loss: 0.05879 test_loss: 0.08766 \n",
      "[ 83/100] train_loss: 0.07262 valid_loss: 0.07092 test_loss: 0.09557 \n",
      "[ 84/100] train_loss: 0.06768 valid_loss: 0.06170 test_loss: 0.09044 \n",
      "[ 85/100] train_loss: 0.06769 valid_loss: 0.06322 test_loss: 0.09239 \n",
      "[ 86/100] train_loss: 0.06668 valid_loss: 0.06633 test_loss: 0.09474 \n",
      "[ 87/100] train_loss: 0.06693 valid_loss: 0.05971 test_loss: 0.08785 \n",
      "[ 88/100] train_loss: 0.06983 valid_loss: 0.05937 test_loss: 0.09078 \n",
      "[ 89/100] train_loss: 0.06770 valid_loss: 0.06396 test_loss: 0.09096 \n",
      "[ 90/100] train_loss: 0.07048 valid_loss: 0.06117 test_loss: 0.09402 \n",
      "[ 91/100] train_loss: 0.06518 valid_loss: 0.06258 test_loss: 0.08832 \n",
      "[ 92/100] train_loss: 0.06878 valid_loss: 0.06426 test_loss: 0.09473 \n",
      "[ 93/100] train_loss: 0.07000 valid_loss: 0.06450 test_loss: 0.08824 \n",
      "[ 94/100] train_loss: 0.06371 valid_loss: 0.06697 test_loss: 0.09086 \n",
      "[ 95/100] train_loss: 0.06526 valid_loss: 0.05990 test_loss: 0.08732 \n",
      "[ 96/100] train_loss: 0.06199 valid_loss: 0.06535 test_loss: 0.09702 \n",
      "[ 97/100] train_loss: 0.06390 valid_loss: 0.06720 test_loss: 0.09356 \n",
      "[ 98/100] train_loss: 0.06740 valid_loss: 0.06181 test_loss: 0.09460 \n",
      "[ 99/100] train_loss: 0.06654 valid_loss: 0.06746 test_loss: 0.09120 \n",
      "[100/100] train_loss: 0.06790 valid_loss: 0.07005 test_loss: 0.09833 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils.net import PTPNet\n",
    "from utils.training import train_model\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "n_epochs = 100\n",
    "\n",
    "train_loader = dl_train\n",
    "valid_loader = dl_valid\n",
    "test_loader = dl_test\n",
    "\n",
    "model = PTPNet(1,1,32).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5.E-5)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([1.9])).cuda()\n",
    "fn = '../data/refit/network_weights/REFIT_dishwasher_network_weights.pth'\n",
    "model, train_loss, valid_loss, test_loss = train_model(model, batch_size, n_epochs, fn, train_loader, valid_loader, test_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e040173-5751-4b4b-9566-5f01716adb57",
   "metadata": {},
   "source": [
    "## Washing-machine case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f74515ab-9442-40f4-bb6a-264782bd3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "APPLIANCE = ['washing_machine']\n",
    "THRESHOLD = [20.]\n",
    "MIN_ON = [1600. / 60]\n",
    "MIN_OFF = [800. / 60]\n",
    "\n",
    "METER = 'aggregate'\n",
    "SEQ_LEN = 60*8\n",
    "BORDER = 16\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "MAX_POWER = 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cccfbc7-7b3a-4c13-be3f-017d2f4a58c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import get_status\n",
    "original_meter = []\n",
    "ds_appliance = []\n",
    "ds_status = []\n",
    "houses = [1,2,3,5,7,8,9,10,11,13,15,16,17,18,19,20,21,6]\n",
    "\n",
    "\n",
    "for i in houses:\n",
    "    ds = pd.read_feather('../data/refit/feather_files/washing_machine/REFIT_%d.feather' %i)\n",
    "    ds.set_index('datetime', inplace=True)\n",
    "    \n",
    "    meter = ds[METER]\n",
    "    appliances = ds[APPLIANCE]\n",
    "    \n",
    "    status = pd.DataFrame()\n",
    "    for a in range(len(APPLIANCE)):\n",
    "        status = pd.concat([status, get_status(ds[APPLIANCE[a]], THRESHOLD[a], MIN_OFF[a], MIN_ON[a])], axis=1)\n",
    "    \n",
    "    original_meter.append(meter)\n",
    "    ds_appliance.append(appliances)\n",
    "    ds_status.append(status)\n",
    "\n",
    "ds_len = [len(original_meter[i]) for i in range(len(houses))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3537cf55-30c0-4091-8bda-8bc2e24d0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils.preprocessing import Power\n",
    "\n",
    "ds_house_total  = [Power(original_meter[i], ds_appliance[i], ds_status[i],SEQ_LEN, BORDER, MAX_POWER, False) for i in range(len(houses))]\n",
    "ds_house_train  = [Power(original_meter[i][:int(0.8*ds_len[i])], \n",
    "                         ds_appliance[i][:int(0.8*ds_len[i])], \n",
    "                         ds_status[i][:int(0.8*ds_len[i])],\n",
    "                         SEQ_LEN, BORDER, MAX_POWER, True) for i in range(len(houses))]\n",
    "ds_house_valid  = [Power(original_meter[i][int(0.8*ds_len[i]):], \n",
    "                         ds_appliance[i][int(0.8*ds_len[i]):], \n",
    "                         ds_status[i][int(0.8*ds_len[i]):],\n",
    "                         SEQ_LEN, BORDER, MAX_POWER, False) for i in range(len(houses))]\n",
    "\n",
    "ds_train      = torch.utils.data.ConcatDataset([ds_house_train[i] for i in range(len(houses)-1)])\n",
    "ds_valid      = torch.utils.data.ConcatDataset([ds_house_valid[i] for i in range(len(houses)-1)])\n",
    "\n",
    "dl_train = DataLoader(dataset = ds_train, batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "dl_valid = DataLoader(dataset = ds_valid, batch_size = BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "dl_test = DataLoader(dataset = ds_house_total[-1], batch_size = BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e197fdf4-b3bd-4419-81bf-752687dcac85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1/200] train_loss: 0.31964 valid_loss: 0.22513 test_loss: 0.11162 \n",
      "Validation loss decreased (inf --> 0.225135).  Saving model ...\n",
      "[  2/200] train_loss: 0.20309 valid_loss: 0.19694 test_loss: 0.08264 \n",
      "Validation loss decreased (0.225135 --> 0.196940).  Saving model ...\n",
      "[  3/200] train_loss: 0.18170 valid_loss: 0.17775 test_loss: 0.07107 \n",
      "Validation loss decreased (0.196940 --> 0.177750).  Saving model ...\n",
      "[  4/200] train_loss: 0.16533 valid_loss: 0.16160 test_loss: 0.06801 \n",
      "Validation loss decreased (0.177750 --> 0.161597).  Saving model ...\n",
      "[  5/200] train_loss: 0.16097 valid_loss: 0.15898 test_loss: 0.06337 \n",
      "Validation loss decreased (0.161597 --> 0.158979).  Saving model ...\n",
      "[  6/200] train_loss: 0.16022 valid_loss: 0.16080 test_loss: 0.06329 \n",
      "[  7/200] train_loss: 0.14983 valid_loss: 0.15092 test_loss: 0.05631 \n",
      "Validation loss decreased (0.158979 --> 0.150919).  Saving model ...\n",
      "[  8/200] train_loss: 0.15451 valid_loss: 0.14392 test_loss: 0.05520 \n",
      "Validation loss decreased (0.150919 --> 0.143917).  Saving model ...\n",
      "[  9/200] train_loss: 0.15431 valid_loss: 0.13891 test_loss: 0.05419 \n",
      "Validation loss decreased (0.143917 --> 0.138909).  Saving model ...\n",
      "[ 10/200] train_loss: 0.14605 valid_loss: 0.14354 test_loss: 0.04907 \n",
      "[ 11/200] train_loss: 0.14152 valid_loss: 0.14502 test_loss: 0.05136 \n",
      "[ 12/200] train_loss: 0.14380 valid_loss: 0.14145 test_loss: 0.04843 \n",
      "[ 13/200] train_loss: 0.14288 valid_loss: 0.13557 test_loss: 0.04863 \n",
      "Validation loss decreased (0.138909 --> 0.135566).  Saving model ...\n",
      "[ 14/200] train_loss: 0.13614 valid_loss: 0.15194 test_loss: 0.04878 \n",
      "[ 15/200] train_loss: 0.13483 valid_loss: 0.13091 test_loss: 0.05156 \n",
      "Validation loss decreased (0.135566 --> 0.130912).  Saving model ...\n",
      "[ 16/200] train_loss: 0.13417 valid_loss: 0.13434 test_loss: 0.04733 \n",
      "[ 17/200] train_loss: 0.13835 valid_loss: 0.13623 test_loss: 0.04818 \n",
      "[ 18/200] train_loss: 0.13251 valid_loss: 0.13691 test_loss: 0.04488 \n",
      "[ 19/200] train_loss: 0.13751 valid_loss: 0.13803 test_loss: 0.04574 \n",
      "[ 20/200] train_loss: 0.13529 valid_loss: 0.14579 test_loss: 0.04808 \n",
      "[ 21/200] train_loss: 0.13024 valid_loss: 0.13076 test_loss: 0.04776 \n",
      "Validation loss decreased (0.130912 --> 0.130756).  Saving model ...\n",
      "[ 22/200] train_loss: 0.13184 valid_loss: 0.14227 test_loss: 0.04365 \n",
      "[ 23/200] train_loss: 0.12781 valid_loss: 0.12899 test_loss: 0.04718 \n",
      "Validation loss decreased (0.130756 --> 0.128989).  Saving model ...\n",
      "[ 24/200] train_loss: 0.12616 valid_loss: 0.13183 test_loss: 0.04508 \n",
      "[ 25/200] train_loss: 0.12998 valid_loss: 0.13575 test_loss: 0.04309 \n",
      "[ 26/200] train_loss: 0.12767 valid_loss: 0.12522 test_loss: 0.04259 \n",
      "Validation loss decreased (0.128989 --> 0.125223).  Saving model ...\n",
      "[ 27/200] train_loss: 0.12226 valid_loss: 0.13255 test_loss: 0.04058 \n",
      "[ 28/200] train_loss: 0.12297 valid_loss: 0.13285 test_loss: 0.04250 \n",
      "[ 29/200] train_loss: 0.12437 valid_loss: 0.14044 test_loss: 0.04345 \n",
      "[ 30/200] train_loss: 0.11868 valid_loss: 0.13696 test_loss: 0.03949 \n",
      "[ 31/200] train_loss: 0.12498 valid_loss: 0.13528 test_loss: 0.03885 \n",
      "[ 32/200] train_loss: 0.11857 valid_loss: 0.13643 test_loss: 0.03872 \n",
      "[ 33/200] train_loss: 0.12382 valid_loss: 0.14743 test_loss: 0.03859 \n",
      "[ 34/200] train_loss: 0.11722 valid_loss: 0.13187 test_loss: 0.04063 \n",
      "[ 35/200] train_loss: 0.11698 valid_loss: 0.12755 test_loss: 0.04064 \n",
      "[ 36/200] train_loss: 0.11636 valid_loss: 0.13385 test_loss: 0.03827 \n",
      "[ 37/200] train_loss: 0.11956 valid_loss: 0.14875 test_loss: 0.03696 \n",
      "[ 38/200] train_loss: 0.11281 valid_loss: 0.12304 test_loss: 0.03848 \n",
      "Validation loss decreased (0.125223 --> 0.123039).  Saving model ...\n",
      "[ 39/200] train_loss: 0.11572 valid_loss: 0.13856 test_loss: 0.03670 \n",
      "[ 40/200] train_loss: 0.11553 valid_loss: 0.13069 test_loss: 0.04137 \n",
      "[ 41/200] train_loss: 0.11655 valid_loss: 0.12695 test_loss: 0.03631 \n",
      "[ 42/200] train_loss: 0.11313 valid_loss: 0.16751 test_loss: 0.03521 \n",
      "[ 43/200] train_loss: 0.11000 valid_loss: 0.12352 test_loss: 0.03551 \n",
      "[ 44/200] train_loss: 0.10762 valid_loss: 0.13898 test_loss: 0.03697 \n",
      "[ 45/200] train_loss: 0.11081 valid_loss: 0.12757 test_loss: 0.03638 \n",
      "[ 46/200] train_loss: 0.11465 valid_loss: 0.13300 test_loss: 0.03758 \n",
      "[ 47/200] train_loss: 0.11318 valid_loss: 0.12042 test_loss: 0.03414 \n",
      "Validation loss decreased (0.123039 --> 0.120422).  Saving model ...\n",
      "[ 48/200] train_loss: 0.10928 valid_loss: 0.12858 test_loss: 0.03510 \n",
      "[ 49/200] train_loss: 0.10444 valid_loss: 0.12580 test_loss: 0.03961 \n",
      "[ 50/200] train_loss: 0.10784 valid_loss: 0.12405 test_loss: 0.03718 \n",
      "[ 51/200] train_loss: 0.10558 valid_loss: 0.12416 test_loss: 0.03523 \n",
      "[ 52/200] train_loss: 0.10836 valid_loss: 0.12545 test_loss: 0.03925 \n",
      "[ 53/200] train_loss: 0.10685 valid_loss: 0.11839 test_loss: 0.03879 \n",
      "Validation loss decreased (0.120422 --> 0.118390).  Saving model ...\n",
      "[ 54/200] train_loss: 0.10903 valid_loss: 0.13122 test_loss: 0.03492 \n",
      "[ 55/200] train_loss: 0.10628 valid_loss: 0.12529 test_loss: 0.03689 \n",
      "[ 56/200] train_loss: 0.10318 valid_loss: 0.12507 test_loss: 0.03945 \n",
      "[ 57/200] train_loss: 0.10983 valid_loss: 0.13352 test_loss: 0.03419 \n",
      "[ 58/200] train_loss: 0.10721 valid_loss: 0.11654 test_loss: 0.03410 \n",
      "Validation loss decreased (0.118390 --> 0.116535).  Saving model ...\n",
      "[ 59/200] train_loss: 0.10855 valid_loss: 0.11260 test_loss: 0.03572 \n",
      "Validation loss decreased (0.116535 --> 0.112603).  Saving model ...\n",
      "[ 60/200] train_loss: 0.10334 valid_loss: 0.12557 test_loss: 0.03657 \n",
      "[ 61/200] train_loss: 0.10480 valid_loss: 0.12540 test_loss: 0.03529 \n",
      "[ 62/200] train_loss: 0.10055 valid_loss: 0.12319 test_loss: 0.03774 \n",
      "[ 63/200] train_loss: 0.10653 valid_loss: 0.12347 test_loss: 0.03953 \n",
      "[ 64/200] train_loss: 0.10808 valid_loss: 0.13620 test_loss: 0.03271 \n",
      "[ 65/200] train_loss: 0.10338 valid_loss: 0.11494 test_loss: 0.03607 \n",
      "[ 66/200] train_loss: 0.10540 valid_loss: 0.12502 test_loss: 0.03537 \n",
      "[ 67/200] train_loss: 0.09538 valid_loss: 0.14371 test_loss: 0.03628 \n",
      "[ 68/200] train_loss: 0.10407 valid_loss: 0.11782 test_loss: 0.03898 \n",
      "[ 69/200] train_loss: 0.10103 valid_loss: 0.14673 test_loss: 0.03255 \n",
      "[ 70/200] train_loss: 0.10426 valid_loss: 0.12858 test_loss: 0.03355 \n",
      "[ 71/200] train_loss: 0.09772 valid_loss: 0.13024 test_loss: 0.03683 \n",
      "[ 72/200] train_loss: 0.10224 valid_loss: 0.12386 test_loss: 0.03732 \n",
      "[ 73/200] train_loss: 0.09837 valid_loss: 0.11745 test_loss: 0.03654 \n",
      "[ 74/200] train_loss: 0.10122 valid_loss: 0.13012 test_loss: 0.03555 \n",
      "[ 75/200] train_loss: 0.09945 valid_loss: 0.12894 test_loss: 0.03179 \n",
      "[ 76/200] train_loss: 0.10002 valid_loss: 0.12252 test_loss: 0.03119 \n",
      "[ 77/200] train_loss: 0.09853 valid_loss: 0.12515 test_loss: 0.03476 \n",
      "[ 78/200] train_loss: 0.09828 valid_loss: 0.12157 test_loss: 0.03410 \n",
      "[ 79/200] train_loss: 0.10069 valid_loss: 0.12607 test_loss: 0.03271 \n",
      "[ 80/200] train_loss: 0.10008 valid_loss: 0.11757 test_loss: 0.03529 \n",
      "[ 81/200] train_loss: 0.09676 valid_loss: 0.12741 test_loss: 0.04464 \n",
      "[ 82/200] train_loss: 0.09947 valid_loss: 0.12818 test_loss: 0.03736 \n",
      "[ 83/200] train_loss: 0.09639 valid_loss: 0.11727 test_loss: 0.03814 \n",
      "[ 84/200] train_loss: 0.09220 valid_loss: 0.13401 test_loss: 0.03387 \n",
      "[ 85/200] train_loss: 0.09336 valid_loss: 0.17758 test_loss: 0.02874 \n",
      "[ 86/200] train_loss: 0.10021 valid_loss: 0.12012 test_loss: 0.03314 \n",
      "[ 87/200] train_loss: 0.09909 valid_loss: 0.14766 test_loss: 0.03640 \n",
      "[ 88/200] train_loss: 0.09350 valid_loss: 0.12127 test_loss: 0.03377 \n",
      "[ 89/200] train_loss: 0.09444 valid_loss: 0.12850 test_loss: 0.03479 \n",
      "[ 90/200] train_loss: 0.09525 valid_loss: 0.13280 test_loss: 0.03475 \n",
      "[ 91/200] train_loss: 0.09656 valid_loss: 0.14104 test_loss: 0.03243 \n",
      "[ 92/200] train_loss: 0.10147 valid_loss: 0.12801 test_loss: 0.02987 \n",
      "[ 93/200] train_loss: 0.09376 valid_loss: 0.13861 test_loss: 0.02742 \n",
      "[ 94/200] train_loss: 0.09617 valid_loss: 0.11967 test_loss: 0.03753 \n",
      "[ 95/200] train_loss: 0.09287 valid_loss: 0.12360 test_loss: 0.03157 \n",
      "[ 96/200] train_loss: 0.09423 valid_loss: 0.13207 test_loss: 0.02953 \n",
      "[ 97/200] train_loss: 0.09140 valid_loss: 0.11714 test_loss: 0.03405 \n",
      "[ 98/200] train_loss: 0.09267 valid_loss: 0.12804 test_loss: 0.03156 \n",
      "[ 99/200] train_loss: 0.09449 valid_loss: 0.13082 test_loss: 0.03356 \n",
      "[100/200] train_loss: 0.09599 valid_loss: 0.13418 test_loss: 0.03223 \n",
      "[101/200] train_loss: 0.09576 valid_loss: 0.13183 test_loss: 0.03355 \n",
      "[102/200] train_loss: 0.09213 valid_loss: 0.12214 test_loss: 0.03141 \n",
      "[103/200] train_loss: 0.09085 valid_loss: 0.12314 test_loss: 0.02976 \n",
      "[104/200] train_loss: 0.08912 valid_loss: 0.11585 test_loss: 0.03424 \n",
      "[105/200] train_loss: 0.09250 valid_loss: 0.14978 test_loss: 0.03774 \n",
      "[106/200] train_loss: 0.09328 valid_loss: 0.13543 test_loss: 0.02823 \n",
      "[107/200] train_loss: 0.09273 valid_loss: 0.16399 test_loss: 0.02925 \n",
      "[108/200] train_loss: 0.09198 valid_loss: 0.15083 test_loss: 0.03089 \n",
      "[109/200] train_loss: 0.09480 valid_loss: 0.16831 test_loss: 0.02973 \n",
      "[110/200] train_loss: 0.09169 valid_loss: 0.12509 test_loss: 0.03777 \n",
      "[111/200] train_loss: 0.08900 valid_loss: 0.12699 test_loss: 0.03697 \n",
      "[112/200] train_loss: 0.08925 valid_loss: 0.12695 test_loss: 0.03087 \n",
      "[113/200] train_loss: 0.08884 valid_loss: 0.12243 test_loss: 0.03200 \n",
      "[114/200] train_loss: 0.09148 valid_loss: 0.12023 test_loss: 0.03317 \n",
      "[115/200] train_loss: 0.09123 valid_loss: 0.12574 test_loss: 0.03368 \n",
      "[116/200] train_loss: 0.09261 valid_loss: 0.12576 test_loss: 0.03117 \n",
      "[117/200] train_loss: 0.08986 valid_loss: 0.13452 test_loss: 0.03419 \n",
      "[118/200] train_loss: 0.08935 valid_loss: 0.12667 test_loss: 0.03535 \n",
      "[119/200] train_loss: 0.08577 valid_loss: 0.12950 test_loss: 0.03520 \n",
      "[120/200] train_loss: 0.08522 valid_loss: 0.13462 test_loss: 0.03083 \n",
      "[121/200] train_loss: 0.08936 valid_loss: 0.14383 test_loss: 0.03049 \n",
      "[122/200] train_loss: 0.08697 valid_loss: 0.12779 test_loss: 0.03252 \n",
      "[123/200] train_loss: 0.09215 valid_loss: 0.14583 test_loss: 0.02675 \n",
      "[124/200] train_loss: 0.09019 valid_loss: 0.13595 test_loss: 0.02682 \n",
      "[125/200] train_loss: 0.09077 valid_loss: 0.12484 test_loss: 0.02800 \n",
      "[126/200] train_loss: 0.09004 valid_loss: 0.12577 test_loss: 0.03257 \n",
      "[127/200] train_loss: 0.09093 valid_loss: 0.12766 test_loss: 0.02843 \n",
      "[128/200] train_loss: 0.08633 valid_loss: 0.12598 test_loss: 0.03304 \n",
      "[129/200] train_loss: 0.08964 valid_loss: 0.13551 test_loss: 0.03075 \n",
      "[130/200] train_loss: 0.08802 valid_loss: 0.12770 test_loss: 0.02956 \n",
      "[131/200] train_loss: 0.08636 valid_loss: 0.10953 test_loss: 0.02987 \n",
      "Validation loss decreased (0.112603 --> 0.109525).  Saving model ...\n",
      "[132/200] train_loss: 0.08673 valid_loss: 0.13458 test_loss: 0.02956 \n",
      "[133/200] train_loss: 0.08793 valid_loss: 0.13299 test_loss: 0.02806 \n",
      "[134/200] train_loss: 0.08524 valid_loss: 0.12013 test_loss: 0.03517 \n",
      "[135/200] train_loss: 0.08724 valid_loss: 0.11902 test_loss: 0.03246 \n",
      "[136/200] train_loss: 0.08625 valid_loss: 0.12148 test_loss: 0.02929 \n",
      "[137/200] train_loss: 0.08373 valid_loss: 0.13032 test_loss: 0.02890 \n",
      "[138/200] train_loss: 0.08579 valid_loss: 0.12159 test_loss: 0.03218 \n",
      "[139/200] train_loss: 0.08421 valid_loss: 0.12414 test_loss: 0.02712 \n",
      "[140/200] train_loss: 0.08917 valid_loss: 0.12749 test_loss: 0.02818 \n",
      "[141/200] train_loss: 0.08701 valid_loss: 0.11563 test_loss: 0.03305 \n",
      "[142/200] train_loss: 0.08495 valid_loss: 0.12255 test_loss: 0.03153 \n",
      "[143/200] train_loss: 0.08551 valid_loss: 0.13440 test_loss: 0.02828 \n",
      "[144/200] train_loss: 0.07946 valid_loss: 0.12241 test_loss: 0.02825 \n",
      "[145/200] train_loss: 0.08406 valid_loss: 0.12883 test_loss: 0.03117 \n",
      "[146/200] train_loss: 0.08576 valid_loss: 0.12654 test_loss: 0.02993 \n",
      "[147/200] train_loss: 0.08018 valid_loss: 0.12266 test_loss: 0.03193 \n",
      "[148/200] train_loss: 0.08672 valid_loss: 0.12260 test_loss: 0.04299 \n",
      "[149/200] train_loss: 0.07936 valid_loss: 0.12560 test_loss: 0.03497 \n",
      "[150/200] train_loss: 0.07936 valid_loss: 0.13128 test_loss: 0.03015 \n",
      "[151/200] train_loss: 0.08736 valid_loss: 0.11692 test_loss: 0.02981 \n",
      "[152/200] train_loss: 0.08123 valid_loss: 0.11245 test_loss: 0.03177 \n",
      "[153/200] train_loss: 0.08563 valid_loss: 0.11802 test_loss: 0.02637 \n",
      "[154/200] train_loss: 0.08380 valid_loss: 0.12696 test_loss: 0.02905 \n",
      "[155/200] train_loss: 0.08263 valid_loss: 0.13674 test_loss: 0.03255 \n",
      "[156/200] train_loss: 0.08316 valid_loss: 0.12823 test_loss: 0.02889 \n",
      "[157/200] train_loss: 0.07873 valid_loss: 0.11980 test_loss: 0.02766 \n",
      "[158/200] train_loss: 0.07678 valid_loss: 0.13732 test_loss: 0.02825 \n",
      "[159/200] train_loss: 0.08384 valid_loss: 0.14230 test_loss: 0.02666 \n",
      "[160/200] train_loss: 0.08145 valid_loss: 0.13109 test_loss: 0.02915 \n",
      "[161/200] train_loss: 0.08204 valid_loss: 0.13306 test_loss: 0.02874 \n",
      "[162/200] train_loss: 0.07939 valid_loss: 0.13244 test_loss: 0.02903 \n",
      "[163/200] train_loss: 0.07934 valid_loss: 0.11625 test_loss: 0.03113 \n",
      "[164/200] train_loss: 0.07799 valid_loss: 0.12816 test_loss: 0.02972 \n",
      "[165/200] train_loss: 0.08236 valid_loss: 0.13409 test_loss: 0.03329 \n",
      "[166/200] train_loss: 0.07789 valid_loss: 0.12133 test_loss: 0.03165 \n",
      "[167/200] train_loss: 0.08201 valid_loss: 0.12213 test_loss: 0.03100 \n",
      "[168/200] train_loss: 0.08334 valid_loss: 0.13778 test_loss: 0.03210 \n",
      "[169/200] train_loss: 0.08130 valid_loss: 0.12599 test_loss: 0.03144 \n",
      "[170/200] train_loss: 0.07884 valid_loss: 0.15966 test_loss: 0.02670 \n",
      "[171/200] train_loss: 0.08001 valid_loss: 0.12272 test_loss: 0.03472 \n",
      "[172/200] train_loss: 0.08243 valid_loss: 0.13325 test_loss: 0.02773 \n",
      "[173/200] train_loss: 0.07840 valid_loss: 0.12915 test_loss: 0.03096 \n",
      "[174/200] train_loss: 0.08123 valid_loss: 0.12453 test_loss: 0.02798 \n",
      "[175/200] train_loss: 0.07991 valid_loss: 0.12701 test_loss: 0.02685 \n",
      "[176/200] train_loss: 0.08377 valid_loss: 0.14564 test_loss: 0.02748 \n",
      "[177/200] train_loss: 0.08157 valid_loss: 0.12502 test_loss: 0.03230 \n",
      "[178/200] train_loss: 0.07930 valid_loss: 0.15469 test_loss: 0.02893 \n",
      "[179/200] train_loss: 0.07943 valid_loss: 0.11413 test_loss: 0.03463 \n",
      "[180/200] train_loss: 0.07480 valid_loss: 0.11702 test_loss: 0.02947 \n",
      "[181/200] train_loss: 0.07564 valid_loss: 0.11523 test_loss: 0.02935 \n",
      "[182/200] train_loss: 0.07918 valid_loss: 0.12038 test_loss: 0.03136 \n",
      "[183/200] train_loss: 0.07988 valid_loss: 0.13077 test_loss: 0.02458 \n",
      "[184/200] train_loss: 0.07842 valid_loss: 0.10851 test_loss: 0.03136 \n",
      "Validation loss decreased (0.109525 --> 0.108511).  Saving model ...\n",
      "[185/200] train_loss: 0.08283 valid_loss: 0.11080 test_loss: 0.03541 \n",
      "[186/200] train_loss: 0.07358 valid_loss: 0.11039 test_loss: 0.02773 \n",
      "[187/200] train_loss: 0.07961 valid_loss: 0.12404 test_loss: 0.02886 \n",
      "[188/200] train_loss: 0.07952 valid_loss: 0.13783 test_loss: 0.02741 \n",
      "[189/200] train_loss: 0.08058 valid_loss: 0.12590 test_loss: 0.03625 \n",
      "[190/200] train_loss: 0.07694 valid_loss: 0.12376 test_loss: 0.02837 \n",
      "[191/200] train_loss: 0.07776 valid_loss: 0.11828 test_loss: 0.02992 \n",
      "[192/200] train_loss: 0.07437 valid_loss: 0.12964 test_loss: 0.02493 \n",
      "[193/200] train_loss: 0.07772 valid_loss: 0.13264 test_loss: 0.02757 \n",
      "[194/200] train_loss: 0.07879 valid_loss: 0.11689 test_loss: 0.02950 \n",
      "[195/200] train_loss: 0.07873 valid_loss: 0.12064 test_loss: 0.03007 \n",
      "[196/200] train_loss: 0.07589 valid_loss: 0.12205 test_loss: 0.02780 \n",
      "[197/200] train_loss: 0.07530 valid_loss: 0.12417 test_loss: 0.02932 \n",
      "[198/200] train_loss: 0.07964 valid_loss: 0.12802 test_loss: 0.03046 \n",
      "[199/200] train_loss: 0.07225 valid_loss: 0.11674 test_loss: 0.02498 \n",
      "[200/200] train_loss: 0.07313 valid_loss: 0.12609 test_loss: 0.02569 \n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from utils.net import PTPNet\n",
    "from utils.training import train_model\n",
    "\n",
    "batch_size = BATCH_SIZE\n",
    "n_epochs = 200\n",
    "\n",
    "train_loader = dl_train\n",
    "valid_loader = dl_valid\n",
    "test_loader = dl_test\n",
    "\n",
    "model = PTPNet(1,1,32).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=5.E-5)\n",
    "#criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([2.9])).cuda()\n",
    "fn = '../data/refit/network_weights/REFIT_washingmachine_network_weights.pth'\n",
    "model, train_loss, valid_loss, test_loss = train_model(model, batch_size, n_epochs, fn, train_loader, valid_loader, test_loader, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9434991-37cf-4d74-8257-3858a7c7699c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf0c23-44b0-4b56-95e9-734318a25bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
